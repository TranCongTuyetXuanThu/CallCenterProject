{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "# Kiểm tra xem GPU có sẵn hay không, nếu không, sử dụng CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Di chuyển mô hình và dữ liệu lên device\n",
    "model.to(device)\n",
    "data = data.to(device)\n",
    "targets = targets.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1],\n",
      "        [1, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        ...,\n",
      "        [0, 1, 0],\n",
      "        [1, 0, 0],\n",
      "        [0, 0, 1]])\n",
      "tensor([[1, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [0, 1, 0],\n",
      "        ...,\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 1],\n",
      "        [1, 0, 0]])\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.0742e-04, 2.2218e-04, 4.7107e-04,  ..., 3.2646e-04,\n",
      "          1.0598e-03, 3.0864e-03],\n",
      "         [3.8089e-03, 1.1963e-03, 2.5364e-03,  ..., 1.7577e-03,\n",
      "          5.7062e-03, 1.6618e-02],\n",
      "         ...,\n",
      "         [1.9064e-07, 2.5339e-08, 3.6193e-08,  ..., 1.6972e-08,\n",
      "          4.1270e-08, 4.9305e-08],\n",
      "         [2.0723e-07, 4.5802e-08, 4.1823e-08,  ..., 5.1683e-08,\n",
      "          1.0393e-07, 8.0843e-08],\n",
      "         [5.4068e-07, 7.8605e-08, 4.5975e-08,  ..., 3.4725e-08,\n",
      "          4.5185e-08, 5.0358e-08]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.3553e-04, 6.2131e-03, 6.9165e-04,  ..., 4.7209e-03,\n",
      "          3.4085e-04, 2.4235e-03],\n",
      "         [1.2682e-03, 3.3453e-02, 3.7240e-03,  ..., 2.5419e-02,\n",
      "          1.8353e-03, 1.3049e-02],\n",
      "         ...,\n",
      "         [7.6417e-07, 2.2129e-08, 2.8496e-08,  ..., 4.5062e-07,\n",
      "          2.5333e-07, 4.1039e-08],\n",
      "         [6.3314e-07, 2.0388e-08, 5.6619e-08,  ..., 5.5118e-08,\n",
      "          3.4663e-08, 2.8148e-08],\n",
      "         [5.2096e-07, 4.7260e-08, 7.1747e-08,  ..., 7.8106e-08,\n",
      "          6.8039e-09, 3.2708e-08]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0039e-02, 1.0344e-03, 6.6614e-03,  ..., 2.2504e-03,\n",
      "          3.7208e-04, 8.8805e-04],\n",
      "         [5.4053e-02, 5.5696e-03, 3.5867e-02,  ..., 1.2117e-02,\n",
      "          2.0034e-03, 4.7815e-03],\n",
      "         ...,\n",
      "         [7.4343e-06, 8.9628e-08, 2.2032e-07,  ..., 2.2083e-06,\n",
      "          1.3306e-06, 7.1634e-07],\n",
      "         [6.5508e-06, 7.7924e-08, 1.1874e-07,  ..., 2.5038e-07,\n",
      "          9.3895e-08, 1.1411e-07],\n",
      "         [5.6506e-06, 7.8276e-08, 8.5946e-08,  ..., 6.6101e-08,\n",
      "          3.2326e-08, 6.6438e-08]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.2953e-03, 2.8448e-03, 1.6970e-03,  ..., 3.4425e-04,\n",
      "          9.0062e-05, 1.0089e-03],\n",
      "         [2.8511e-02, 1.5317e-02, 9.1372e-03,  ..., 1.8535e-03,\n",
      "          4.8492e-04, 5.4322e-03],\n",
      "         ...,\n",
      "         [2.4882e-08, 4.5288e-08, 3.1861e-08,  ..., 1.0103e-07,\n",
      "          3.9321e-08, 5.9788e-08],\n",
      "         [2.6562e-08, 5.0709e-08, 4.6464e-08,  ..., 2.3816e-08,\n",
      "          1.5761e-08, 3.6040e-08],\n",
      "         [1.7865e-08, 4.6299e-08, 7.0991e-08,  ..., 3.7802e-08,\n",
      "          3.6244e-08, 4.9461e-08]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.8104e-04, 1.3332e-03, 2.4709e-04,  ..., 7.4633e-04,\n",
      "          6.0610e-05, 1.0648e-04],\n",
      "         [2.0516e-03, 7.1783e-03, 1.3304e-03,  ..., 4.0185e-03,\n",
      "          3.2634e-04, 5.7334e-04],\n",
      "         ...,\n",
      "         [1.3041e-06, 5.4960e-08, 3.7992e-08,  ..., 8.7318e-07,\n",
      "          1.8531e-06, 2.2422e-06],\n",
      "         [1.1435e-06, 2.5934e-08, 5.8729e-08,  ..., 3.2348e-07,\n",
      "          3.6517e-07, 8.1254e-08],\n",
      "         [1.1830e-06, 2.2448e-08, 9.0086e-08,  ..., 2.9960e-08,\n",
      "          4.0906e-08, 4.2905e-08]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.6389e-02, 4.9821e-03, 4.8071e-03,  ..., 2.0995e-03,\n",
      "          1.1785e-02, 1.4968e-02],\n",
      "         [1.9593e-01, 2.6825e-02, 2.5883e-02,  ..., 1.1304e-02,\n",
      "          6.3453e-02, 8.0594e-02],\n",
      "         ...,\n",
      "         [3.9769e-08, 7.1455e-08, 1.1503e-07,  ..., 8.2924e-08,\n",
      "          2.2939e-08, 1.7422e-08],\n",
      "         [6.0402e-08, 7.0600e-08, 7.2066e-08,  ..., 5.2759e-08,\n",
      "          1.8624e-08, 2.0788e-08],\n",
      "         [1.2895e-07, 2.4331e-08, 5.8491e-08,  ..., 4.9699e-08,\n",
      "          1.1243e-08, 4.6223e-08]]])\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [4.5113e-03, 1.6542e-03, 3.6349e-03,  ..., 7.5231e-04,\n",
      "          4.4326e-03, 2.4584e-03],\n",
      "         [2.4290e-02, 8.9068e-03, 1.9571e-02,  ..., 4.0507e-03,\n",
      "          2.3866e-02, 1.3237e-02],\n",
      "         ...,\n",
      "         [1.1586e-07, 1.4243e-08, 2.4788e-08,  ..., 8.6669e-08,\n",
      "          5.5801e-08, 6.9458e-08],\n",
      "         [7.5125e-08, 2.2840e-08, 5.7336e-08,  ..., 5.3849e-08,\n",
      "          6.0826e-08, 3.9137e-08],\n",
      "         [1.2098e-07, 1.2079e-08, 2.5288e-08,  ..., 1.8635e-08,\n",
      "          3.0737e-08, 3.5691e-08]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [4.3991e-03, 8.5222e-03, 2.0233e-05,  ..., 3.6862e-03,\n",
      "          1.5839e-03, 1.8479e-03],\n",
      "         [2.3686e-02, 4.5886e-02, 1.0894e-04,  ..., 1.9847e-02,\n",
      "          8.5281e-03, 9.9497e-03],\n",
      "         ...,\n",
      "         [3.5022e-08, 4.4290e-08, 7.7756e-08,  ..., 8.0744e-08,\n",
      "          7.7906e-08, 7.6618e-08],\n",
      "         [9.0351e-08, 5.5633e-08, 3.8075e-08,  ..., 4.4241e-08,\n",
      "          1.1993e-07, 9.5380e-08],\n",
      "         [8.5175e-08, 2.0925e-08, 3.3826e-08,  ..., 1.2491e-08,\n",
      "          4.7287e-08, 9.3210e-08]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.1460e-03, 1.0873e-02, 2.4614e-02,  ..., 5.4887e-03,\n",
      "          3.0663e-02, 2.2340e-02],\n",
      "         [6.1704e-03, 5.8541e-02, 1.3253e-01,  ..., 2.9552e-02,\n",
      "          1.6510e-01, 1.2029e-01],\n",
      "         ...,\n",
      "         [3.6587e-06, 1.3425e-08, 6.6760e-08,  ..., 3.0873e-08,\n",
      "          7.6860e-08, 4.7839e-08],\n",
      "         [2.5739e-06, 3.2616e-08, 5.2664e-08,  ..., 2.7784e-08,\n",
      "          1.0086e-07, 9.6444e-08],\n",
      "         [3.5938e-06, 4.3790e-08, 2.2489e-08,  ..., 3.7807e-08,\n",
      "          5.6205e-08, 6.5109e-08]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7137e-03, 1.3692e-03, 1.9383e-03,  ..., 9.5505e-05,\n",
      "          2.4160e-04, 1.6495e-03],\n",
      "         [9.2269e-03, 7.3722e-03, 1.0436e-02,  ..., 5.1422e-04,\n",
      "          1.3009e-03, 8.8814e-03],\n",
      "         ...,\n",
      "         [8.5601e-07, 6.5406e-08, 4.4771e-08,  ..., 9.3724e-08,\n",
      "          8.6028e-08, 3.9079e-08],\n",
      "         [7.4868e-07, 7.7698e-08, 6.9759e-08,  ..., 4.5434e-08,\n",
      "          1.2765e-07, 5.4668e-08],\n",
      "         [1.1376e-06, 3.5976e-08, 2.1889e-08,  ..., 4.8456e-08,\n",
      "          3.5992e-08, 2.1608e-08]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.1272e-01, 3.1404e-02, 1.5979e-02,  ..., 2.5139e-03,\n",
      "          7.0353e-03, 1.0579e-03],\n",
      "         [6.0691e-01, 1.6909e-01, 8.6033e-02,  ..., 1.3536e-02,\n",
      "          3.7880e-02, 5.6962e-03],\n",
      "         ...,\n",
      "         [3.1743e-04, 1.8663e-07, 1.6344e-07,  ..., 1.0692e-07,\n",
      "          1.0152e-07, 3.2198e-08],\n",
      "         [3.1810e-04, 4.0027e-08, 2.9235e-08,  ..., 2.5268e-08,\n",
      "          1.3376e-07, 4.8177e-08],\n",
      "         [3.1834e-04, 3.4405e-08, 2.5223e-08,  ..., 5.8058e-08,\n",
      "          1.3571e-07, 1.8657e-07]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.5380e-04, 3.2223e-03, 4.1307e-03,  ..., 8.1380e-03,\n",
      "          5.7333e-03, 5.7348e-03],\n",
      "         [1.9049e-03, 1.7350e-02, 2.2241e-02,  ..., 4.3817e-02,\n",
      "          3.0870e-02, 3.0878e-02],\n",
      "         ...,\n",
      "         [1.3630e-05, 9.9331e-08, 1.0453e-07,  ..., 2.1261e-08,\n",
      "          4.4150e-08, 3.0967e-08],\n",
      "         [1.3753e-05, 1.2723e-08, 9.0895e-08,  ..., 1.7995e-08,\n",
      "          7.1964e-08, 4.3367e-08],\n",
      "         [1.2902e-05, 3.3903e-08, 4.6662e-08,  ..., 3.7420e-08,\n",
      "          2.1102e-08, 5.0661e-08]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the data from the .pt file\n",
    "label_train = torch.load(\"label_train.pt\")\n",
    "label_test = torch.load(\"label_test.pt\")\n",
    "data_train = torch.load(\"data_train.pt\")\n",
    "data_test = torch.load(\"data_test.pt\")\n",
    "\n",
    "# Now, you can work with the loaded data, which could be a PyTorch tensor or other Python objects.\n",
    "print(label_train)\n",
    "print(label_test)\n",
    "print(data_train)\n",
    "print(data_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6023, 3])\n",
      "torch.Size([1506, 3])\n",
      "torch.Size([6023, 128, 1500])\n",
      "torch.Size([1506, 128, 1500])\n"
     ]
    }
   ],
   "source": [
    "print(label_train.shape)\n",
    "print(label_test.shape)\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data loaders\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(data_train, label_train)\n",
    "test_dataset = TensorDataset(data_test, label_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the LSTM model\n",
    "# class SimpleLSTM(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "#         super(SimpleLSTM, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "#         out, _ = self.lstm(x, (h0, c0))\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomLSTM(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "#         super(CustomLSTM, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.fc1 = nn.Linear(hidden_size, 64)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.dropout1 = nn.Dropout(0.4)\n",
    "#         self.fc2 = nn.Linear(64, 32)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.dropout2 = nn.Dropout(0.4)\n",
    "#         self.fc3 = nn.Linear(32, num_classes)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "#         out, _ = self.lstm(x, (h0, c0))\n",
    "#         out = self.fc1(out[:, -1, :])\n",
    "#         out = self.relu1(out)\n",
    "#         out = self.dropout1(out)\n",
    "#         out = self.fc2(out)\n",
    "#         out = self.relu2(out)\n",
    "#         out = self.dropout2(out)\n",
    "#         out = self.fc3(out)\n",
    "#         out = self.softmax(out)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# class RNN_LSTM(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "#         super(RNN_LSTM, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, num_classes)  # Thay đổi số lớp đầu ra thành 3\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Set initial hidden and cell states\n",
    "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "#         # Forward propagate LSTM\n",
    "#         out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "#         # Lấy đầu ra của bước cuối cùng\n",
    "#         out = out[:, -1, :]\n",
    "\n",
    "#         # Đưa qua lớp fully connected\n",
    "#         out = self.fc(out)\n",
    "\n",
    "#         return out\n",
    "\n",
    "# # Initialize the model\n",
    "# input_size = 1500  # Số chiều của đầu vào (cần điều chỉnh phù hợp với dữ liệu của bạn)\n",
    "# hidden_size = 128\n",
    "# num_layers = 2\n",
    "# num_classes = 3  # Số lớp đầu ra là 3\n",
    "\n",
    "# # Khởi tạo mô hình\n",
    "# model = RNN_LSTM(input_size, hidden_size, num_layers, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear1 = nn.Linear(128, 64)\n",
    "        #self.linear2 = nn.Linear(64, 32)\n",
    "        self.linear3 = nn.Linear(32, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=2, batch_first=True, dropout=0.2, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 128).to(x.device)  # Số lớp (num_layers) là 2\n",
    "        c0 = torch.zeros(2, x.size(0), 128).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        out = self.linear1(out)\n",
    "        #out = self.linear2(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input_size = 1500  # Input features (adjust based on your data)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 3\n",
    "\n",
    "#model = SimpleLSTM(input_size, hidden_size, num_layers, num_classes)\n",
    "#model = CustomLSTM(input_size, hidden_size, num_layers, num_classes)\n",
    "model = LSTMModel( input_size, hidden_size, num_layers, num_classes)\n",
    "#model = RNN_LSTM( input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.0351791233612746\n",
      "Epoch [2/10], Loss: 1.0081684520004919\n",
      "Epoch [3/10], Loss: 0.9701611213583164\n",
      "Epoch [4/10], Loss: 0.9383038834289268\n",
      "Epoch [5/10], Loss: 0.9060143828392029\n",
      "Epoch [6/10], Loss: 0.8510925413439514\n",
      "Epoch [7/10], Loss: 0.7939566995101001\n",
      "Epoch [8/10], Loss: 0.7435371074726973\n",
      "Epoch [9/10], Loss: 0.6839905302360575\n",
      "Epoch [10/10], Loss: 0.6484600866913165\n",
      "Accuracy on the test set: 46.14873837981408%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.8994634375370368\n",
      "Epoch [2/10], Loss: 0.8974518605640956\n",
      "Epoch [3/10], Loss: 0.9019246716347952\n",
      "Epoch [4/10], Loss: 0.9184131303792278\n",
      "Epoch [5/10], Loss: 1.0015696779129997\n",
      "Epoch [6/10], Loss: 0.915267271970315\n",
      "Epoch [7/10], Loss: 0.8932461536750591\n",
      "Epoch [8/10], Loss: 0.8914022057775467\n",
      "Epoch [9/10], Loss: 0.8845253924213389\n",
      "Epoch [10/10], Loss: 0.8764180903712278\n",
      "Accuracy on the test set: 48.00796812749004%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader)}\")\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {100 * correct / total}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
