{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6967817,"sourceType":"datasetVersion","datasetId":3927882}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-15T10:02:30.604212Z","iopub.execute_input":"2023-11-15T10:02:30.605205Z","iopub.status.idle":"2023-11-15T10:02:31.639944Z","shell.execute_reply.started":"2023-11-15T10:02:30.605161Z","shell.execute_reply":"2023-11-15T10:02:31.639043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:02:31.641499Z","iopub.execute_input":"2023-11-15T10:02:31.641867Z","iopub.status.idle":"2023-11-15T10:02:43.947999Z","shell.execute_reply.started":"2023-11-15T10:02:31.641842Z","shell.execute_reply":"2023-11-15T10:02:43.946637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch, torchvision, os\nfrom torchsummary import summary\nimport numpy as np\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:02:43.950282Z","iopub.execute_input":"2023-11-15T10:02:43.950650Z","iopub.status.idle":"2023-11-15T10:02:48.376625Z","shell.execute_reply.started":"2023-11-15T10:02:43.950617Z","shell.execute_reply":"2023-11-15T10:02:48.375778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(file):\n    with open(file, 'rb') as f:\n        X_test = np.load(f)\n        X_valid = np.load(f)\n        X_train = np.load(f)\n        Y_test = np.load(f)\n        Y_valid = np.load(f)\n        Y_train = np.load(f)\n    return X_test, X_valid, X_train, Y_test, Y_valid, Y_train","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:02:48.378503Z","iopub.execute_input":"2023-11-15T10:02:48.378951Z","iopub.status.idle":"2023-11-15T10:02:48.384741Z","shell.execute_reply.started":"2023-11-15T10:02:48.378923Z","shell.execute_reply":"2023-11-15T10:02:48.383779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, X_valid, X_train, Y_test, Y_valid, Y_train = load_data('/kaggle/input/dpl-project/features_labels_15000.npy')\n\nprint(f'X_train:{X_train.shape}, y_train:{Y_train.shape}')\nprint(f'X_valid:{X_valid.shape}, Y_valid:{Y_valid.shape}')\nprint(f'X_test:{X_test.shape}, y_test:{Y_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:02:48.385898Z","iopub.execute_input":"2023-11-15T10:02:48.386182Z","iopub.status.idle":"2023-11-15T10:03:16.443203Z","shell.execute_reply.started":"2023-11-15T10:02:48.386157Z","shell.execute_reply":"2023-11-15T10:03:16.442044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['positive', 'neutral', 'negative']\nfor ind, label in enumerate(labels):\n#     print('Total sample of',label,'=',resulty[resulty[:,ind]==1].shape[0])\n    total = np.concatenate((Y_train[:,ind], Y_valid[:,ind], Y_test[:,ind])).sum()\n    print('Total sample of',label,'=',total)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:03:16.444752Z","iopub.execute_input":"2023-11-15T10:03:16.445066Z","iopub.status.idle":"2023-11-15T10:03:16.451967Z","shell.execute_reply.started":"2023-11-15T10:03:16.445039Z","shell.execute_reply":"2023-11-15T10:03:16.450952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train_ = ['positive','neutral','negative']\n# Y_train_ = ['positive','neutral','negative']\n# for i in range(3):    \n#     selected_indices = np.where(Y_train[:, i] == 1)[0]\n#     selected_rows = Y_train[Y_train[:, i] == 1]\n#     Y_train_[i] = np.array(selected_rows)[:1783,:]\n#     print(Y_train_[i].shape)\n#     selected_data = [X_train[ind,:,:,:] for ind in selected_indices[:1783]]\n#     X_train_[i] = np.array(selected_data)\n#     print(X_train_[i].shape)\n# Y_train = np.concatenate((Y_train_[0], Y_train_[1],Y_train_[2]), axis=0)\n# X_train = np.concatenate((X_train_[0], X_train_[1],X_train_[2]), axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T08:40:01.708741Z","iopub.execute_input":"2023-11-15T08:40:01.709462Z","iopub.status.idle":"2023-11-15T08:40:01.722846Z","shell.execute_reply.started":"2023-11-15T08:40:01.709423Z","shell.execute_reply":"2023-11-15T08:40:01.721849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model flow\nclass define_model(nn.Module):\n\n    # Define layers\n    def __init__(self, num_emotions):\n        super().__init__()\n\n        transformer_layer = nn.TransformerEncoderLayer(\n            d_model=40, #####################\n            nhead=4,\n            dim_feedforward=512,\n            dropout=0.4,\n            activation='relu'\n        )\n        self.transformer_maxpool = nn.MaxPool2d(kernel_size=[1,4], stride=[1,4])\n        self.transformer_encoder = nn.TransformerEncoder(transformer_layer, num_layers=4)\n\n        #maxpool: reshape (width, height)\n        #conv: reshape (channel)\n        conv2d_layer = nn.Sequential(\n            nn.Conv2d(\n                in_channels=2,\n                out_channels=16,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(16),#######\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Dropout(p=0.3),\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(32),#######\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4, stride=4),\n            nn.Dropout(p=0.3),\n            nn.Conv2d(\n                in_channels=32,\n                out_channels=64,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(64),#######\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4, stride=4),\n            nn.Dropout(p=0.3),\n        )\n        self.conv2Dblock1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=2,\n                out_channels=16,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Dropout(p=0.3),\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4, stride=4),\n            nn.Dropout(p=0.3),\n            nn.Conv2d(\n                in_channels=32,\n                out_channels=64,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4, stride=4),\n            nn.Dropout(p=0.3),\n        )\n        self.conv2Dblock2 = conv2d_layer\n\n        self.fc1_layer = nn.Linear(1792*2+40, 1800)\n        self.act1 = nn.ReLU()\n#         self.fc2_layer = nn.Linear(1800, 9)\n#         self.act1 = nn.ReLU()\n        self.fc2_layer = nn.Linear(1800, num_emotions)\n        self.softmax_out = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        conv2d_embedding1 = self.conv2Dblock1(x)\n        conv2d_embedding1 = torch.flatten(conv2d_embedding1, start_dim = 1)\n\n        conv2d_embedding2 = self.conv2Dblock2(x)\n        conv2d_embedding2 = torch.flatten(conv2d_embedding2, start_dim = 1)\n\n        x_maxpool = self.transformer_maxpool(x)\n        # x_maxpool_reduced = torch.squeeze(x_maxpool,1) \n        x_maxpool_reduced = x_maxpool.resize(x_maxpool.shape[0], 40, 450) \n        x = x_maxpool_reduced.permute(2,0,1) #rearrange dims\n        transformer_output = self.transformer_encoder(x)\n        transformer_embedding = torch.mean(transformer_output, dim = 0)\n\n        complete_embedding = torch.cat([conv2d_embedding1, conv2d_embedding2, transformer_embedding], dim = 1)\n        fc1 = self.fc1_layer(complete_embedding)\n        ac1 = self.act1(fc1)\n#         fc2 = self.fc2_layer(ac1)\n#         ac2 = self.act1(fc2)\n        output_logits = self.fc2_layer(ac1)\n        output_softmax = self.softmax_out(output_logits)\n        return output_logits, output_softmaxz","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:03:22.608996Z","iopub.execute_input":"2023-11-15T10:03:22.609672Z","iopub.status.idle":"2023-11-15T10:03:22.627838Z","shell.execute_reply.started":"2023-11-15T10:03:22.609637Z","shell.execute_reply":"2023-11-15T10:03:22.626901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def distribute_model(model):\n#     if torch.cuda.device_count() < 2:\n#         raise ValueError(\"At least 2 GPUs are required for this operation.\")\n#     model = nn.DataParallel(model)\n#     return model","metadata":{"execution":{"iopub.status.busy":"2023-11-15T08:40:01.744827Z","iopub.execute_input":"2023-11-15T08:40:01.745134Z","iopub.status.idle":"2023-11-15T08:40:01.756418Z","shell.execute_reply.started":"2023-11-15T08:40:01.745109Z","shell.execute_reply":"2023-11-15T08:40:01.755628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training step\ndef make_train_step(model, criterion, optimizer):\n    def train_step(X, Y):\n        output_logits, output_softmax = model(X)\n        predictions = torch.argmax(output_softmax, dim=1)\n        Y = torch.argmax(Y, dim=1)\n        accuracy = torch.sum(Y==predictions)/float(len(Y))\n        loss = criterion(output_logits, Y)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        return loss.item(), accuracy*100\n    return train_step\n\n#validation step\ndef make_validate_fnc(model, criterion):\n    def validate(X,Y):\n        with torch.no_grad():\n            model.eval()\n            output_logits, output_softmax = model(X)\n            predictions = torch.argmax(output_softmax, dim=1)\n            Y = torch.argmax(Y, dim=1)\n            accuracy = torch.sum(Y==predictions)/float(len(Y))\n            loss = criterion(output_logits, Y)\n        return loss.item(), accuracy*100\n    return validate","metadata":{"execution":{"iopub.status.busy":"2023-11-15T08:40:01.759114Z","iopub.execute_input":"2023-11-15T08:40:01.759393Z","iopub.status.idle":"2023-11-15T08:40:01.770003Z","shell.execute_reply.started":"2023-11-15T08:40:01.759368Z","shell.execute_reply":"2023-11-15T08:40:01.769264Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(model_path):\n    model = define_model(3)\n    model.eval()\n    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n#     model.load_state_dict(torch.load(model_path))\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-15T08:40:01.771030Z","iopub.execute_input":"2023-11-15T08:40:01.771325Z","iopub.status.idle":"2023-11-15T08:40:01.779397Z","shell.execute_reply.started":"2023-11-15T08:40:01.771301Z","shell.execute_reply":"2023-11-15T08:40:01.778499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_save_checkpoint():\n    def save_checkpoint(optimizer, model, epoch, filename):\n        checkpoint_dict = {\n            'optimizer': optimizer.state_dict(),\n            'model': model.state_dict(),\n            'epoch': epoch\n        }\n        torch.save(checkpoint_dict, filename)\n    return save_checkpoint\n\ndef load_checkpoint(optimizer, model, filename):\n    checkpoint_dict = torch.load(filename)\n    epoch = checkpoint_dict['epoch']\n    model.load_state_dict(checkpoint_dict['model'])\n    if optimizer is not None:\n        optimizer.load_state_dict(checkpoint_dict['optimizer'])\n    return epoch, model","metadata":{"execution":{"iopub.status.busy":"2023-11-15T08:40:01.780476Z","iopub.execute_input":"2023-11-15T08:40:01.780716Z","iopub.status.idle":"2023-11-15T08:40:01.789608Z","shell.execute_reply.started":"2023-11-15T08:40:01.780694Z","shell.execute_reply":"2023-11-15T08:40:01.788912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions_dict ={\n    '0':'positive',\n    '1':'neutral',\n    '2':'negative'}\n\n# Define optimizer\ndef choose_optimizer(kind, learning_rate, w_decay, model):\n  if kind == 'SGD':\n    return torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=w_decay, momentum=0.3)\n  if kind == 'ADAM':\n    return torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=w_decay, eps = 1e-08)\n# Define loss/ criterion\ndef criterion(predictions, targets):\n    return nn.CrossEntropyLoss()(input=predictions, target=targets)\n\n# Define the model and distribute it across the two GPUs\nmodel = define_model(len(emotions_dict))\n# model = distribute_model(model)\nprint('Number of trainable params: ', sum(p.numel() for p in model.parameters()))\n\nlr = 0.01\noptimizer = choose_optimizer('SGD',lr,1e-3, model)\nsave_checkpoint = make_save_checkpoint()\ntrain_step = make_train_step(model, criterion, optimizer)\nvalidate = make_validate_fnc(model, criterion)\n\n# Define your device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# device2 = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n\nmodel.to(device)\nprint(f'GPU model: {torch.cuda.get_device_name(0)}')\n\n# Train your model on multiple GPUs\n# if torch.cuda.device_count() > 1:\n#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n#     model = nn.DataParallel(model, device_ids=[0, 1])\n\ntrain_losses = []\nvalid_losses = []","metadata":{"execution":{"iopub.status.busy":"2023-11-15T08:40:01.790790Z","iopub.execute_input":"2023-11-15T08:40:01.791049Z","iopub.status.idle":"2023-11-15T08:40:04.853706Z","shell.execute_reply.started":"2023-11-15T08:40:01.791027Z","shell.execute_reply":"2023-11-15T08:40:04.852649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(optimizer, model, num_epochs, X_train, Y_train, X_valid, Y_valid, list_acc, list_loss):\n    train_size = X_train.shape[0]\n    minibatch = 16\n#     acc_max = 0\n    for epoch in range(num_epochs):\n        #set to train phase\n        model.train()\n\n        train_indices = np.random.permutation(train_size)\n        X_train = X_train[train_indices,:,:,:]\n        Y_train = Y_train[train_indices,:]\n\n        epoch_acc = 0\n        epoch_loss = 0\n        num_iterations = int(train_size/minibatch)\n\n        for i in range(num_iterations+1):\n            batch_start = i*minibatch\n            batch_end = min(batch_start + minibatch, train_size)\n            actual_batch_size = batch_end - batch_start\n\n            X = X_train[batch_start:batch_end,:,:,:]\n            Y = Y_train[batch_start:batch_end,:]\n\n            X_tensor = torch.tensor(X, device = device).float()\n            Y_tensor = torch.tensor(Y, dtype = torch.long, device = device)\n\n            loss, acc = train_step(X_tensor, Y_tensor)\n\n            epoch_acc += acc * actual_batch_size / train_size\n            epoch_loss += loss * actual_batch_size / train_size\n\n        X_valid_tensor = torch.tensor(X_valid, device = device).float()\n        Y_valid_tensor = torch.tensor(Y_valid, dtype = torch.long, device = device)\n        valid_loss, valid_acc, = validate(X_valid_tensor,Y_valid_tensor)\n        list_acc[0].append(epoch_acc.cpu().numpy())\n        list_acc[1].append(valid_acc.cpu().numpy())\n        list_loss[0].append(epoch_loss)\n        list_loss[1].append(valid_loss)\n#         if acc_max > int(epoch_acc):\n#           continue\n#         acc_max = epoch_acc\n#         checkpoint_filename = 'cnn_transformerFINAL-{:03d}.pkl'.format(epoch)\n#         save_checkpoint(optimizer, model, epoch, checkpoint_filename)\n        torch.save(model.state_dict(),'model'+str(epoch)+'.pt')\n\n        print(f'\\nEpoch {epoch} --- loss:{epoch_loss:.3f}, Epoch accuracy:{epoch_acc:.2f}%, Validation loss:{valid_loss:.3f}, Validation accuracy:{valid_acc:.3f}')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T08:40:04.855361Z","iopub.execute_input":"2023-11-15T08:40:04.855752Z","iopub.status.idle":"2023-11-15T08:40:04.867504Z","shell.execute_reply.started":"2023-11-15T08:40:04.855716Z","shell.execute_reply":"2023-11-15T08:40:04.866529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_epochs = 100\n# list_acc = [[],[]]\n# list_loss = [[],[]]\n# train(optimizer, model, num_epochs, X_train, Y_train, X_valid[:1000,:,:,:], Y_valid[:1000,:], list_acc, list_loss)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T08:40:04.868714Z","iopub.execute_input":"2023-11-15T08:40:04.869029Z","iopub.status.idle":"2023-11-15T09:27:20.740620Z","shell.execute_reply.started":"2023-11-15T08:40:04.869005Z","shell.execute_reply":"2023-11-15T09:27:20.739463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(range(num_epochs),list_acc[0])\nplt.plot(range(num_epochs),list_acc[1])\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\ntitle = 'SGD lr:' + str(lr) + 'weight_decay:1e-3'\nplt.title(title)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T09:30:28.408015Z","iopub.execute_input":"2023-11-15T09:30:28.408483Z","iopub.status.idle":"2023-11-15T09:30:28.748251Z","shell.execute_reply.started":"2023-11-15T09:30:28.408449Z","shell.execute_reply":"2023-11-15T09:30:28.747267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(range(num_epochs),list_loss[0])\nplt.plot(range(num_epochs),list_loss[1])\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.title(title)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T09:30:29.529629Z","iopub.execute_input":"2023-11-15T09:30:29.529989Z","iopub.status.idle":"2023-11-15T09:30:29.784726Z","shell.execute_reply.started":"2023-11-15T09:30:29.529961Z","shell.execute_reply":"2023-11-15T09:30:29.783620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"def load_model(model_path):\n    model = define_model(3)\n    model.eval()\n#     model.load_state_dict(torch.load(model_path, map_location='cpu'))\n    model.load_state_dict(torch.load(model_path))\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:03:30.502230Z","iopub.execute_input":"2023-11-15T10:03:30.502637Z","iopub.status.idle":"2023-11-15T10:03:30.507485Z","shell.execute_reply.started":"2023-11-15T10:03:30.502606Z","shell.execute_reply":"2023-11-15T10:03:30.506416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def metric(y, y_hat):\n  # Compute F1 score for each label\n    labels = [0,1,2]\n    emotions = {0: 'positive',\n               1: 'neutral',\n               2: 'negative'}\n    f1_scores_per_label = [f1_score(y, y_hat, labels=[label], average='weighted') for label in labels]\n\n    # Compute average F1 score across all labels\n    average_f1_score = np.mean(f1_scores_per_label)\n\n    # Display F1 scores for each label and the average F1 score\n    for label in emotions.keys():\n        print(\"F1 scores for each label:\",emotions[label],':', f1_scores_per_label[label])\n    print(\"Average F1 score:\", average_f1_score)\n    \n    accuracy = torch.sum(y==y_hat)/float(len(y))\n#     print('F1_score of every label: ', labels)\n#     print('Average F1: ',round(statistics.mean(labels.values()),2))\n    print('Accuracy: ', accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:03:30.820359Z","iopub.execute_input":"2023-11-15T10:03:30.820725Z","iopub.status.idle":"2023-11-15T10:03:30.827471Z","shell.execute_reply.started":"2023-11-15T10:03:30.820695Z","shell.execute_reply":"2023-11-15T10:03:30.826490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(X_test,Y_test):\n    model = load_model('/kaggle/working/model98.pt')\n    model.eval()\n\n    X_test_tensor = torch.tensor(X_test).float()\n    Y_test_tensor = torch.tensor(Y_test, dtype = torch.long)\n    \n    minibatch = 128\n    num_iterations = int(X_test.shape[0]/minibatch)\n    list_Y = torch.argmax(Y_test_tensor, dim=1)\n    list_Yhat = torch.tensor(())\n    for i in range(num_iterations+1):\n        batch_start = i*minibatch\n        batch_end = min(batch_start + minibatch, X_test.shape[0])\n        actual_batch_size = batch_end - batch_start\n        \n        X = X_test[batch_start:batch_end,:,:,:]\n        X_tensor = torch.tensor(X).float()\n\n        output_logits, output_softmax = model(X_tensor)\n        predictions = torch.argmax(output_softmax, dim=1)\n\n        list_Yhat = torch.cat((list_Yhat, predictions), dim = 0)\n    \n    metric(list_Y, list_Yhat)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:13:38.015325Z","iopub.execute_input":"2023-11-15T10:13:38.016285Z","iopub.status.idle":"2023-11-15T10:13:38.025006Z","shell.execute_reply.started":"2023-11-15T10:13:38.016231Z","shell.execute_reply":"2023-11-15T10:13:38.023877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_hat = test(X_test, Y_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:13:38.873856Z","iopub.execute_input":"2023-11-15T10:13:38.874761Z","iopub.status.idle":"2023-11-15T10:14:34.391812Z","shell.execute_reply.started":"2023-11-15T10:13:38.874725Z","shell.execute_reply":"2023-11-15T10:14:34.390748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import roc_auc_score\n# import numpy as np\n# from sklearn.preprocessing import label_binarize\n\n# # Binarize the true labels for each class\n# Y_binarized = label_binarize(Y_test, classes=[0, 1, 2])\n\n# # Compute AUC-ROC for each class\n# auc_scores_per_class = [roc_auc_score(Y_binarized[:, i], Y_hat == i) for i in range(Y_binarized.shape[1])]\n# auc_scores_per_class","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:16:05.057992Z","iopub.execute_input":"2023-11-15T10:16:05.058728Z","iopub.status.idle":"2023-11-15T10:16:05.063551Z","shell.execute_reply.started":"2023-11-15T10:16:05.058689Z","shell.execute_reply":"2023-11-15T10:16:05.062527Z"},"trusted":true},"execution_count":null,"outputs":[]}]}