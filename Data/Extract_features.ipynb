{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to-do list\n",
    "1) extract feature\n",
    "2) label ([exc, hap, sur] 21%,[neu, fru] 42%,[fea, ang, sad, dis] 38%) -> 1 file.csv\n",
    "3) process dims (double), bias (remove)\n",
    "- add noise\n",
    "- process real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchaudio\n",
    "# !pip install torch\n",
    "# !pip install soundfile\n",
    "#!pip install PySoundFile\n",
    "# print(torchaudio.__version__)\n",
    "# print(torch.__version__)\n",
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import torchaudio\n",
    "from io import StringIO\n",
    "import torch\n",
    "import sndhdr\n",
    "import soundfile\n",
    "import csv,glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) EXTRACT FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_data():\n",
    "    # Define the path to your data folder\n",
    "    data_folder_path = os.path.join('..', 'IEMOCAP_release_full')\n",
    "\n",
    "    # Create a link to the data folder\n",
    "    data_folder_link = os.path.dirname(os.path.abspath(data_folder_path))\n",
    "\n",
    "    # Print the link\n",
    "    return(data_folder_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Đọc link file\n",
    "def read_link_wav(type = ('sentences', 'dialog'), sessions = [1,2,3,4,5]):\n",
    "    source = link_to_data()\n",
    "    link = os.path.join(source,'IEMOCAP_full_release', 'Session'+str(sessions), type, 'wav')\n",
    "    links = {}\n",
    "    if type == 'dialog':\n",
    "        return\n",
    "    for dialog in os.listdir(link):\n",
    "        list_sentence = []\n",
    "        for sentence in os.listdir(os.path.join(link,dialog)):\n",
    "            sentence_link = os.path.join(link, dialog, sentence)\n",
    "            list_sentence.append(sentence_link)\n",
    "        links[dialog] = list_sentence\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#.wav to .pt\n",
    "def read_and_save_mfcc(types = ('dialog','sentences')):\n",
    "    for session in range(1,6):\n",
    "        links = read_link_wav(types, session)\n",
    "        source = link_to_data()\n",
    "        root = os.path.join(source,'IEMOCAP_full_release','Session'+str(session),types)\n",
    "        if os.path.exists(os.path.join(root,'mfcc')):\n",
    "            shutil.rmtree(os.path.join(root,'mfcc'))\n",
    "        os.makedirs(os.path.join(root,'mfcc'))\n",
    "        for dia in links.keys():\n",
    "            if os.path.exists(os.path.join(root,'mfcc',dia)):\n",
    "                shutil.rmtree(os.path.join(root,'mfcc',dia))\n",
    "            os.makedirs(os.path.join(root,'mfcc',dia))\n",
    "            for sen in links[dia]:\n",
    "                try:\n",
    "                    if sndhdr.what(sen).filetype == 'wav':\n",
    "                        waveform, sample_rate = torchaudio.load(sen)\n",
    "                        transform = torchaudio.transforms.MFCC(sample_rate=sample_rate)\n",
    "                        mfcc = transform(waveform)\n",
    "                        output_file = os.path.join(root,'mfcc',dia,os.path.basename(sen)[:-4]+'.pt')\n",
    "                        torch.save(mfcc,output_file)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract feature .wav to .pt\n",
    "# read_and_save_mfcc('sentences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Label + remove noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_shape(file):\n",
    "    mfcc = torch.load(file)\n",
    "    return list(mfcc.shape)\n",
    "def update_sample(categories,session,words):\n",
    "    source = link_to_data()\n",
    "    if len(words)==4:\n",
    "        path_file = os.path.join(source,'IEMOCAP_full_release','Session'+str(session),'sentences','mfcc',words[1][:-5],words[1]+'.pt')\n",
    "        if os.path.exists(path_file):\n",
    "            shape = get_shape(path_file)\n",
    "            with open('processed_label_data.csv',mode = 'a',newline = '') as f:\n",
    "                write = csv.writer(f)\n",
    "                if (words[2]) in categories['positive']:\n",
    "                    write.writerow([words[1],words[2],1,0,0,shape,shape[1:],path_file])\n",
    "                if (words[2]) in categories['neutral']:\n",
    "                    write.writerow([words[1],words[2],0,1,0,shape,shape[1:],path_file])\n",
    "                if (words[2]) in categories['negative']:\n",
    "                    write.writerow([words[1],words[2],0,0,1,shape,shape[1:],path_file])\n",
    "                if (words[2]) in ['xxx','oth']:\n",
    "                    os.remove(path_file)\n",
    "def create_label_file():\n",
    "    source = link_to_data()\n",
    "    categories = {'positive': ['exc', 'hap', 'sur'],\n",
    "                'neutral': ['neu','fru'],\n",
    "                'negative': ['fea','ang','sad','dis']}\n",
    "    header = ['sessionID','labels','positive','neutral','negative','dims','time_shape','path']\n",
    "    with open('processed_label_data.csv',mode='w',newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    for session in range(1,6):\n",
    "        root = os.path.join(source,'IEMOCAP_full_release','Session'+str(session),'dialog','EmoEvaluation','*')\n",
    "        files = glob.glob(root)\n",
    "        for file in files:\n",
    "            if file[-3:] =='txt': \n",
    "                with open(file, 'r') as lines:\n",
    "                    for line in lines:\n",
    "                        words = line.split(\"\\t\")\n",
    "                        update_sample(categories,session,words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_label_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for mono file audio or not\n",
    "def check_mono():\n",
    "    source = link_to_data()\n",
    "    for session in range(1,6):\n",
    "        root = os.path.join(source,'IEMOCAP_full_release','Session'+str(session),'sentences','mfcc')\n",
    "        for dialog in os.listdir(root):\n",
    "            for sentence in os.listdir(os.path.join(root,dialog)):\n",
    "                sample = torch.load(os.path.join(root,dialog,sentence))\n",
    "                if sample.shape[0]!=1:\n",
    "                    return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reform_file_data():\n",
    "    df = pd.read_csv('processed_label_data.csv')\n",
    "    df['dims'] = df['dims'].apply(lambda x: [int(i) for i in x.strip('[]').split(',')])\n",
    "    if str(df['time_shape'].dtype) == 'object':\n",
    "        df['time_shape'] = df['time_shape'].apply(lambda x: x.strip('[]').split(','))\n",
    "    df.to_csv('processed_label_data.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to size(128,1500)\n",
    "def normalize_shape(time_shape):\n",
    "    df = reform_file_data()\n",
    "    for sample in range(len(df)):\n",
    "        tmp_sample = torch.load(df.path[sample])\n",
    "        # if len(tmp_sample.shape) == 3:\n",
    "        #     tmp_sample = tmp_sample.resize(40,tmp_sample.shape[2])\n",
    "        if tmp_sample.shape[2] == time_shape:\n",
    "            continue\n",
    "        if tmp_sample.shape[2] >time_shape:\n",
    "            tmp_sample = tmp_sample[:,:,:time_shape]\n",
    "        while tmp_sample.shape[2]<time_shape:\n",
    "            last_dims = time_shape - tmp_sample.shape[2]\n",
    "            if last_dims > tmp_sample.shape[2]:\n",
    "                tmp_sample = torch.cat((tmp_sample,tmp_sample),dim=2)\n",
    "            else:\n",
    "                tmp_sample = torch.cat((tmp_sample,tmp_sample[:,:,:last_dims]),dim=2)\n",
    "        tmp_sample = torch.cat((tmp_sample,tmp_sample), dim = 0)\n",
    "        torch.save(tmp_sample,df.path[sample])\n",
    "        df['time_shape'][sample] = time_shape\n",
    "        df['dims'][sample] = [40,time_shape]\n",
    "    df.to_csv('processed_shape_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_shape(time_shape):\n",
    "    df = reform_file_data()\n",
    "    for sample in range(len(df)):\n",
    "        tmp_sample = torch.load(df.path[sample])\n",
    "        if list(tmp_sample.shape) != [40,time_shape]:\n",
    "            print(list(tmp_sample.shape))\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Mono before nomalize: ',check_mono())\n",
    "# normalize_shape(900)\n",
    "# print('Mono after nomalize: ',check_mono())\n",
    "# check_shape(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corrNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
