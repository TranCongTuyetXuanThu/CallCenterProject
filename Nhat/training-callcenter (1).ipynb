{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-18T05:56:11.714027Z","iopub.execute_input":"2023-10-18T05:56:11.714591Z","iopub.status.idle":"2023-10-18T05:56:11.964745Z","shell.execute_reply.started":"2023-10-18T05:56:11.714563Z","shell.execute_reply":"2023-10-18T05:56:11.963997Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/iemocap-trainingdata/data_test.pt\n/kaggle/input/iemocap-trainingdata/label_test.pt\n/kaggle/input/iemocap-trainingdata/label_train.pt\n/kaggle/input/iemocap-trainingdata/data_train.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2023-10-18T05:56:13.708585Z","iopub.execute_input":"2023-10-18T05:56:13.709257Z","iopub.status.idle":"2023-10-18T05:56:13.713626Z","shell.execute_reply.started":"2023-10-18T05:56:13.709230Z","shell.execute_reply":"2023-10-18T05:56:13.712980Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# **1. LoadData to DataLoader**","metadata":{}},{"cell_type":"code","source":"random.seed(42)\ntorch.manual_seed(42)\n\nif torch.cuda.is_available():\n  torch.cuda.manual_seed_all(42)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T05:56:15.616979Z","iopub.execute_input":"2023-10-18T05:56:15.617561Z","iopub.status.idle":"2023-10-18T05:56:15.622353Z","shell.execute_reply.started":"2023-10-18T05:56:15.617528Z","shell.execute_reply":"2023-10-18T05:56:15.621622Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Đường dẫn đến các file\ndata_train_iemocap_path = \"/kaggle/input/iemocap-trainingdata/data_train.pt\"  \nlabel_train_iemocap_path = \"/kaggle/input/iemocap-trainingdata/label_train.pt\"\ndata_test_iemocap_path = \"/kaggle/input/iemocap-trainingdata/data_test.pt\"\nlabel_test_iemocap_path = \"/kaggle/input/iemocap-trainingdata/label_test.pt\"\n\n# Load dữ liệu từ các file\ndata_train_iemocap = torch.load(data_train_iemocap_path)\nlabel_train_iemocap = torch.load(label_train_iemocap_path) \ndata_test_iemocap = torch.load(data_test_iemocap_path)\nlabel_test_iemocap = torch.load(label_test_iemocap_path)\n\n# Chuẩn bị DataLoader cho dữ liệu huấn luyện và kiểm tra\nbatch_size = 32  \n\n# Chuẩn bị DataLoader cho dữ liệu huấn luyện và kiểm tra\ntrain_dataset = TensorDataset(data_train_iemocap, label_train_iemocap)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\ntest_dataset = TensorDataset(data_test_iemocap, label_test_iemocap)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Define a custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        sample = {'data': self.data[idx], 'label': self.labels[idx]}\n        return sample\n\n# Create DataLoader for training and testing using the custom dataset\ntrain_dataset_custom = CustomDataset(data_train, label_train)\ntrain_loader_custom = DataLoader(train_dataset_custom, batch_size=batch_size, shuffle=True)\n\ntest_dataset_custom = CustomDataset(data_test, label_test)\ntest_loader_custom = DataLoader(test_dataset_custom, batch_size=batch_size, shuffle=False)\n\n\ndef check_data(data, label):\n  print(f'Shape data: {data.shape}') \n  print(f'Dtype data: {data.dtype}')\n  print(f'Shape label: {label.shape}')\n  print(f'Length: {len(data)}')\n\n\n# Print information about the loaded data\nprint(\"Information about IEMOCAP training data:\")\ncheck_data(data_train_iemocap, label_train_iemocap)\n\nprint(\"\\nInformation about IEMOCAP test data:\")\ncheck_data(data_test_iemocap, label_test_iemocap)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T06:09:42.909571Z","iopub.execute_input":"2023-10-18T06:09:42.909867Z","iopub.status.idle":"2023-10-18T06:09:44.235518Z","shell.execute_reply.started":"2023-10-18T06:09:42.909845Z","shell.execute_reply":"2023-10-18T06:09:44.234892Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Information about IEMOCAP training data:\nShape data: torch.Size([6023, 40, 1500])\nDtype data: torch.float32\nShape label: torch.Size([6023, 3])\nLength: 6023\n\nInformation about IEMOCAP test data:\nShape data: torch.Size([1506, 40, 1500])\nDtype data: torch.float32\nShape label: torch.Size([1506, 3])\nLength: 1506\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Define Neural Network","metadata":{}},{"cell_type":"code","source":"#Adjust hidden nodes and one hidden layer\nimport torch\nimport torch.nn as nn \nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n# Thêm các imports cần thiết\nfrom sklearn.metrics import f1_score, accuracy_score\n\n# import\n\n# import\n\nclass SpeechClassifier(nn.Module):\n\n  def __init__(self, cnn_input_channels, cnn_output_channels,  \n               cnn_kernel_size, cnn_stride,  \n               cnn_pool_kernel_size, cnn_pool_stride,   \n               hidden_size1, hidden_size2, output_size):  \n    \n    super().__init__()\n\n    # CNN block\n    self.cnn = nn.Conv1d(cnn_input_channels, cnn_output_channels,   \n                        cnn_kernel_size, stride=cnn_stride)\n                        \n    self.pool = nn.MaxPool1d(cnn_pool_kernel_size,   \n                             stride=cnn_pool_stride)\n                             \n    \n    # Tính toán kích thước đầu vào\n    conv_out_length = (1500 - cnn_kernel_size) // cnn_pool_kernel_size + 1  \n    self.input_size = cnn_output_channels * conv_out_length     \n\n    self.hidden1 = nn.Linear(self.input_size, hidden_size1)\n    self.hidden2 = nn.Linear(hidden_size1, hidden_size2) \n\n    self.output = nn.Linear(hidden_size2, output_size)\n\n  def forward(self, x):\n    x = self.cnn(x)\n    x = self.pool(x)\n    x = x.view(x.size(0), -1)  \n    x = F.relu(self.hidden1(x))\n    x = F.relu(self.hidden2(x))\n    x = self.output(x)\n    return F.softmax(x, dim=1)\n\n# Define model parameters\ncnn_input_channels = 40  \ncnn_output_channels = 16   \ncnn_kernel_size = 5\ncnn_stride = 1\ncnn_pool_kernel_size = 2  \ncnn_pool_stride = 2\nhidden_size1 = 256 \nhidden_size2 = 512\noutput_size = 3\n\n# Create an instance of the model\nmodel = SpeechClassifier(cnn_input_channels, cnn_output_channels, cnn_kernel_size, cnn_stride,  \n                         cnn_pool_kernel_size, cnn_pool_stride, \n                         hidden_size1, hidden_size2, output_size)\n                         \n# Print the model architecture   \nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-18T06:06:10.666239Z","iopub.execute_input":"2023-10-18T06:06:10.666593Z","iopub.status.idle":"2023-10-18T06:06:11.149692Z","shell.execute_reply.started":"2023-10-18T06:06:10.666565Z","shell.execute_reply":"2023-10-18T06:06:11.148983Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"SpeechClassifier(\n  (cnn): Conv1d(40, 16, kernel_size=(5,), stride=(1,))\n  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (hidden1): Linear(in_features=11968, out_features=256, bias=True)\n  (hidden2): Linear(in_features=256, out_features=512, bias=True)\n  (output): Linear(in_features=512, out_features=3, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# #main\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n# class ComplexNN(nn.Module):\n#     def __init__(self, cnn_input_channels, cnn_output_channels, cnn_kernel_size, cnn_stride, \n#                  cnn_pool_kernel_size, cnn_pool_stride, hidden_size, output_size):\n#         super(ComplexNN, self).__init__()\n        \n#         self.cnn = nn.Conv1d(cnn_input_channels, cnn_output_channels, cnn_kernel_size, stride=cnn_stride)\n#         self.pool = nn.MaxPool1d(cnn_pool_kernel_size, stride=cnn_pool_stride)\n        \n#         self.input_size = cnn_output_channels * ((1500 - cnn_kernel_size) // cnn_pool_kernel_size + 1)\n#         self.hidden = nn.Linear(self.input_size, hidden_size)\n#         self.relu = nn.ReLU()\n        \n#         self.output = nn.Linear(hidden_size, output_size)\n\n#     def forward(self, x):\n#         x = self.cnn(x)\n#         x = self.pool(x)\n#         x = x.view(x.size(0), -1)\n#         x = self.hidden(x)\n#         x = self.relu(x)\n#         x = self.output(x)\n#         x = F.softmax(x, dim=1)\n#         return x\n\n# # Define model parameters\n# cnn_input_channels = 40\n# cnn_output_channels = 16\n# cnn_kernel_size = 5\n# cnn_stride = 1\n# cnn_pool_kernel_size = 2\n# cnn_pool_stride = 2\n# hidden_size = 256\n# output_size = 3\n\n# # Create an instance of the ComplexNN model\n# model = ComplexNN(cnn_input_channels, cnn_output_channels, cnn_kernel_size, cnn_stride,\n#                    cnn_pool_kernel_size, cnn_pool_stride, hidden_size, output_size)\n\n# # Print the model architecture\n# print(model)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-17T05:26:41.096191Z","iopub.execute_input":"2023-10-17T05:26:41.096514Z","iopub.status.idle":"2023-10-17T05:26:41.130077Z","shell.execute_reply.started":"2023-10-17T05:26:41.096490Z","shell.execute_reply":"2023-10-17T05:26:41.129114Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"ComplexNN(\n  (cnn): Conv1d(40, 16, kernel_size=(5,), stride=(1,))\n  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (hidden): Linear(in_features=11968, out_features=128, bias=True)\n  (relu): ReLU()\n  (output): Linear(in_features=128, out_features=3, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"#ADD\nimport torch\nimport torch.nn as nn \nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n# Thêm các imports cần thiết\nfrom sklearn.metrics import f1_score, accuracy_score\n\n# import\n\n# import\n\nclass SpeechClassifier(nn.Module):\n\n  def __init__(self, cnn_input_channels, cnn_output_channels, \n               cnn_kernel_size, cnn_stride, \n               cnn_pool_kernel_size, cnn_pool_stride, \n               hidden_size, output_size):\n    \n    super().__init__()\n    \n    # CNN block\n    self.cnn = nn.Conv1d(cnn_input_channels, cnn_output_channels,  \n                        cnn_kernel_size, stride=cnn_stride)\n                        \n    self.pool = nn.MaxPool1d(cnn_pool_kernel_size,  \n                             stride=cnn_pool_stride)\n                             \n    \n    # Tính toán kích thước đầu vào \n    conv_out_length = (1500 - cnn_kernel_size) // cnn_pool_kernel_size + 1\n    self.input_size = cnn_output_channels * conv_out_length     \n\n    self.hidden = nn.Linear(self.input_size, hidden_size)\n    \n    self.output = nn.Linear(hidden_size, output_size)\n\n  def forward(self, x):\n\n    x = self.cnn(x)\n    x = self.pool(x)\n    \n    x = x.view(x.size(0), -1)\n    \n    x = self.hidden(x)\n    x = F.relu(x)\n    \n    x = self.output(x)\n    \n    return F.softmax(x, dim=1)\n\n# Define model parameters\ncnn_input_channels = 40\ncnn_output_channels = 16\ncnn_kernel_size = 5\ncnn_stride = 1\ncnn_pool_kernel_size = 2\ncnn_pool_stride = 2\nhidden_size = 128\noutput_size = 3\n\n# Create an instance of the ComplexNN model\nmodel = SpeechClassifier(cnn_input_channels, cnn_output_channels, cnn_kernel_size, cnn_stride,\n                   cnn_pool_kernel_size, cnn_pool_stride, hidden_size, output_size)\n\n# Print the model architecture\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-18T06:06:42.161247Z","iopub.execute_input":"2023-10-18T06:06:42.161733Z","iopub.status.idle":"2023-10-18T06:06:42.188143Z","shell.execute_reply.started":"2023-10-18T06:06:42.161707Z","shell.execute_reply":"2023-10-18T06:06:42.187542Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"SpeechClassifier(\n  (cnn): Conv1d(40, 16, kernel_size=(5,), stride=(1,))\n  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (hidden): Linear(in_features=11968, out_features=128, bias=True)\n  (output): Linear(in_features=128, out_features=3, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Training Model","metadata":{}},{"cell_type":"code","source":"\n# Check for GPU availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Move the model to the appropriate device\nmodel.to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)   # Adjust the learning rate as needed\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n# Training loop\nnum_epochs = 100  # Adjust the number of epochs as needed\n\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to training mode\n    running_loss = 0.0\n    \n    for batch_data, batch_labels in train_loader:\n        # Move the data to the appropriate device\n        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(batch_data)\n        loss = criterion(outputs, torch.argmax(batch_labels, dim=1))\n        \n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n        \n        # Update running loss\n        running_loss += loss.item()\n    \n    # Print the average loss for the epoch\n    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n\nprint('Finished Training')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adđ F1-Score & Accuracy after Training\n\n# Check for GPU availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Move the model to the appropriate device\nmodel.to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)   # Adjust the learning rate as needed\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n# Training loop\nnum_epochs = 10  # Adjust the number of epochs as needed\n\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to training mode\n    running_loss = 0.0\n    \n    for batch_data, batch_labels in train_loader:\n        # Move the data to the appropriate device\n        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(batch_data)\n        loss = criterion(outputs, torch.argmax(batch_labels, dim=1))\n        \n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n        \n        # Update running loss\n        running_loss += loss.item()\n    \n    # Print the average loss for the epoch\n    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n\nprint('Finished Training')\n\n# Evaluate on test set\nprint('Evaluating on test set')\n\nmodel.eval()\n\ntest_loss = 0\ncorrect = 0\n\nwith torch.no_grad():\n    for batch_data, batch_labels in test_loader:\n        \n        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n        \n        outputs = model(batch_data)\n        loss = criterion(outputs, torch.argmax(batch_labels, dim=1))\n        \n        test_loss += loss.item() * batch_labels.size(0)\n        \n        _, predicted = torch.max(outputs.data, 1)\n        correct += (predicted == torch.argmax(batch_labels, dim=1)).sum().item()\n        \ntest_loss /= len(test_loader.dataset)\n\nprint(f'Test Loss: {test_loss}')\nprint(f'Test Accuracy: {100*correct/len(test_loader.dataset):.2f}%')\n\n# Lưu model và kết quả\ntorch.save(model.state_dict(), 'best_model.pt')","metadata":{"execution":{"iopub.status.busy":"2023-10-18T06:06:47.158111Z","iopub.execute_input":"2023-10-18T06:06:47.158702Z","iopub.status.idle":"2023-10-18T06:07:03.276337Z","shell.execute_reply.started":"2023-10-18T06:06:47.158672Z","shell.execute_reply":"2023-10-18T06:07:03.275752Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch 1, Loss: 1.2561025979026916\nEpoch 2, Loss: 1.2536841164190302\nEpoch 3, Loss: 1.2560461728030412\nEpoch 4, Loss: 1.2560461731184096\nEpoch 5, Loss: 1.2560461728030412\nEpoch 6, Loss: 1.2554556591800912\nEpoch 7, Loss: 1.254865144926404\nEpoch 8, Loss: 1.2554556591800912\nEpoch 9, Loss: 1.2554556591800912\nEpoch 10, Loss: 1.2560461731184096\nFinished Training\nEvaluating on test set\nTest Loss: 1.2552961495768027\nTest Accuracy: 29.61%\n","output_type":"stream"}]}]}