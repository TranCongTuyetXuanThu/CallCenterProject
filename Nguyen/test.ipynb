{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1kBkXpiH8-_hnprMeAcUgWhvjLAumhCOg","authorship_tag":"ABX9TyPn0HyDYqNOx2ELSjKV7X4T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wH3ppzHRfDeq","executionInfo":{"status":"ok","timestamp":1698583857031,"user_tz":-420,"elapsed":23188,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}},"outputId":"eaef0263-f43d-40cb-a258-0ce95dddf2f3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install pydub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlOg5ZAGcuJr","executionInfo":{"status":"ok","timestamp":1698583871428,"user_tz":-420,"elapsed":6345,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}},"outputId":"0927fdae-3fa9-4b72-aa19-d28767c3b5e7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}]},{"cell_type":"code","source":["import subprocess, os, csv\n","from torch import nn\n","import torch, torchaudio, statistics\n","from pydub import AudioSegment\n","from pydub.silence import detect_nonsilent\n","import pandas as pd\n","import warnings"],"metadata":{"id":"McukFf_5aphR","executionInfo":{"status":"ok","timestamp":1698583876081,"user_tz":-420,"elapsed":4661,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# suppress all warnings\n","warnings.filterwarnings(\"ignore\")\n","# suppress only the UserWarning with message \"At least one mel filterbank has all zero values.\"\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"3nWQ8pw0jQZP","executionInfo":{"status":"ok","timestamp":1698583876081,"user_tz":-420,"elapsed":8,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Model flow\n","class define_model(nn.Module):\n","\n","    # Define layers\n","    def __init__(self, num_emotions):\n","        super().__init__()\n","\n","        transformer_layer = nn.TransformerEncoderLayer(\n","            d_model=40, #####################\n","            nhead=4,\n","            dim_feedforward=512,\n","            dropout=0.4,\n","            activation='relu'\n","        )\n","        self.transformer_maxpool = nn.MaxPool2d(kernel_size=[1,4], stride=[1,4])\n","        self.transformer_encoder = nn.TransformerEncoder(transformer_layer, num_layers=4)\n","\n","        #maxpool: reshape (width, height)\n","        #conv: reshape (channel)\n","        conv2d_layer = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=1,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding=1\n","            ),\n","            nn.BatchNorm2d(16),#######\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(p=0.3),\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=32,\n","                kernel_size=3,\n","                stride=1,\n","                padding=1\n","            ),\n","            nn.BatchNorm2d(32),#######\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=4, stride=4),\n","            nn.Dropout(p=0.3),\n","            nn.Conv2d(\n","                in_channels=32,\n","                out_channels=64,\n","                kernel_size=3,\n","                stride=1,\n","                padding=1\n","            ),\n","            nn.BatchNorm2d(64),#######\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=4, stride=4),\n","            nn.Dropout(p=0.3),\n","        )\n","        self.conv2Dblock1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=1,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding=1\n","            ),\n","            nn.BatchNorm2d(16),#######\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(p=0.3),\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=32,\n","                kernel_size=3,\n","                stride=1,\n","                padding=1\n","            ),\n","            nn.BatchNorm2d(32),#######\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=4, stride=4),\n","            nn.Dropout(p=0.3),\n","            nn.Conv2d(\n","                in_channels=32,\n","                out_channels=64,\n","                kernel_size=3,\n","                stride=1,\n","                padding=1\n","            ),\n","            nn.BatchNorm2d(64),#######\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=4, stride=4),\n","            nn.Dropout(p=0.3),\n","        )\n","        self.conv2Dblock2 = conv2d_layer\n","\n","        self.fc1_layer = nn.Linear(960*2+40, 980)\n","        self.act1 = nn.ReLU()\n","        self.fc2_layer = nn.Linear(980, num_emotions)\n","        self.softmax_out = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        conv2d_embedding1 = self.conv2Dblock1(x)\n","        conv2d_embedding1 = torch.flatten(conv2d_embedding1, start_dim = 1)\n","\n","        conv2d_embedding2 = self.conv2Dblock2(x)\n","        conv2d_embedding2 = torch.flatten(conv2d_embedding2, start_dim = 1)\n","\n","        x_maxpool = self.transformer_maxpool(x)\n","        x_maxpool_reduced = torch.squeeze(x_maxpool,1) ############\n","        x = x_maxpool_reduced.permute(2,0,1) ###########\n","        transformer_output = self.transformer_encoder(x)\n","        transformer_embedding = torch.mean(transformer_output, dim = 0)\n","\n","        complete_embedding = torch.cat([conv2d_embedding1, conv2d_embedding2, transformer_embedding], dim = 1)\n","        fc1 = self.fc1_layer(complete_embedding)\n","        ac1 = self.act1(fc1)\n","        output_logits = self.fc2_layer(ac1)\n","        output_softmax = self.softmax_out(output_logits)\n","        return output_logits, output_softmax"],"metadata":{"id":"NphIprrdafyX","executionInfo":{"status":"ok","timestamp":1698583876081,"user_tz":-420,"elapsed":6,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class preprocess_real_data():\n","    def __init__(self,file):\n","      self.file = file\n","    def mp4_to_wav(self, file):\n","        # Load the MP4 file\n","        # video = VideoFileClip(file)\n","        # # Extract the audio from the video\n","        # audio = video.audio\n","        # # Export the audio as a WAV file\n","        # file = file[:-4]+'.wav'\n","        # audio.write_audiofile(file)\n","        output_file = file.replace('raw_datas', 'wav_datas')\n","        output_file = output_file.split('.')[0] + \".wav\"\n","        subprocess.call(['ffmpeg', '-i', file, output_file])\n","        return output_file\n","    def remove_noise(self, file):\n","        # Detect non-silent parts of the audio\n","        sound_file = AudioSegment.from_wav(file)\n","        non_sil_times = detect_nonsilent(sound_file, min_silence_len=400, silence_thresh=sound_file.dBFS * 0.65)\n","\n","        # Concatenate the non-silent parts of the audio\n","        if len(non_sil_times) > 0:\n","            non_sil_times_concat = [non_sil_times[0]]\n","            if len(non_sil_times) > 1:\n","                for t in non_sil_times[1:]:\n","                    if t[0] - non_sil_times_concat[-1][1] < 100:\n","                        non_sil_times_concat[-1] = (non_sil_times_concat[-1][0], t[1])\n","                    else:\n","                        non_sil_times_concat.append(t)\n","            new_audio = sound_file[non_sil_times_concat[0][0]:non_sil_times_concat[0][1]]\n","            for t in non_sil_times_concat[1:]:\n","                new_audio += sound_file[t[0]:t[1]]\n","        else:\n","            new_audio = sound_file\n","\n","        # Export the new audio file\n","        file_name = file.replace('wav_datas', 'denoised_datas')\n","        file_name = file_name[:-4]+'_denoised.wav'\n","        new_audio.export(file_name, format=\"wav\")\n","        return file_name\n","    def resize(self, file):\n","        tensor = torch.load(file)\n","        tensor1 = tensor[0,:,:]\n","        # tensor2 = tensor[1,:,:]\n","        n = tensor1.shape[-1]//500 + 1\n","        sample1 = torch.zeros((40,n * 500))\n","        sample1[:,:tensor1.shape[-1]] = tensor1\n","        sample1 = torch.transpose(torch.transpose(sample1.reshape((40,500,n)),dim0=0, dim1=2),dim0=1, dim1=2).reshape((n,1,40,500))\n","        return sample1\n","    def save_tensor_file(self, file):\n","        waveform, sample_rate = torchaudio.load(file)\n","        transform = torchaudio.transforms.MFCC(sample_rate=sample_rate)\n","        mfcc = transform(waveform)\n","        file_name = file[:-4]+'.pt'\n","        torch.save(mfcc,file_name)\n","        return file_name\n","    def complete_preprocessing(self, file):\n","      file = self.mp4_to_wav(file)\n","      file = self.remove_noise(file)\n","      file = self.save_tensor_file(file)\n","      tensor = self.resize(file)\n","      return file, tensor\n"],"metadata":{"id":"J8dYFNxIZ4ky","executionInfo":{"status":"ok","timestamp":1698583876081,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def load_model(model_path):\n","    model = define_model(3)\n","    model.eval()\n","    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n","    # model.load_state_dict(torch.load(model_path))\n","    return model"],"metadata":{"id":"DRenZW-aaSf2","executionInfo":{"status":"ok","timestamp":1698583876081,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def predict_1_sample(file_sample, model, preprocesser):\n","    file_sample, tensor = preprocesser.complete_preprocessing(file_sample)\n","    output_logit, output_softmax = model(tensor)\n","    output_softmax = torch.argmax(output_softmax, dim=1)\n","    final_output = max(set(output_softmax.tolist()), key=output_softmax.tolist().count)\n","    emotion_dict = {0: 'positive',\n","                    1: 'neutral',\n","                    2: 'negative'}\n","    label = emotion_dict[final_output]\n","    return final_output, label\n","\n"],"metadata":{"id":"onMFksqDaXSk","executionInfo":{"status":"ok","timestamp":1698583877280,"user_tz":-420,"elapsed":2,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# #predict 1 sample\n","# model = load_model('/content/drive/MyDrive/DPL/model/model2_SGD_200e.pt')\n","# preprocess = preprocess_real_data('ok')\n","# final_output, label = predict_1_sample('file.wav', model, preprocess)\n","# print(label)"],"metadata":{"id":"AeCOE5N_cIxx","executionInfo":{"status":"ok","timestamp":1698583881313,"user_tz":-420,"elapsed":533,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Test for dataset"],"metadata":{"id":"uvxxxmWZZmtV"}},{"cell_type":"code","source":["def extract_label_file(root):\n","  header = ['sessionID','labels','path']\n","  emotion_dict = {\n","      'positive': 0,\n","      'neutral': 1,\n","      'negative': 2\n","  }\n","  with open('test_real_data.csv',mode='w',newline='') as file:\n","          write = csv.writer(file)\n","          write.writerow(header)\n","  df = pd.read_csv('test_real_data.csv')\n","  for file in os.listdir(root):\n","          for sample in os.listdir(os.path.join(root, file)):\n","              processer = preprocess_real_data(0)\n","              path_sample, tensor = processer.complete_preprocessing(os.path.join(root, file, sample))\n","              sample_info = {'sessionID': sample, 'labels': emotion_dict[file],'path': path_sample}\n","              df = pd.concat([df, pd.DataFrame([sample_info])], ignore_index=True)\n","  df.to_csv('test_real_data.csv')"],"metadata":{"id":"2_e3MSJvOwog","executionInfo":{"status":"ok","timestamp":1698583885576,"user_tz":-420,"elapsed":366,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def test_real_data(model_file):\n","  df = pd.read_csv('/content/drive/MyDrive/DPL/test_data/test_real_data.csv')\n","  model = load_model(model_file)\n","  preprocesser = preprocess_real_data('ok')\n","  y = df.labels\n","  y = torch.as_tensor(y)\n","  y_hat = torch.zeros(len(y))\n","  ind_sample = 0\n","  for sample in df.path:\n","    final_output, label = predict_1_sample(sample, model, preprocesser)\n","    y_hat[ind_sample] = final_output\n","    ind_sample += 1\n","  return y, y_hat"],"metadata":{"id":"RliGHo-jZWWg","executionInfo":{"status":"ok","timestamp":1698584435395,"user_tz":-420,"elapsed":315,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# root = '/content/drive/MyDrive/DPL/test_data/raw_datas'\n","# extract_label_file(root)\n","# model_file = '/content/drive/MyDrive/DPL/model/model2_SGD_200e_2.pt'\n","# y, y_hat = test_real_data(model_file)\n","# print(accuracy)"],"metadata":{"id":"Evk5HdQPaPII","executionInfo":{"status":"ok","timestamp":1698587478185,"user_tz":-420,"elapsed":480,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["def metric():\n","  df = pd.read_csv('/content/drive/MyDrive/DPL/test_data/test_real_data.csv')\n","  labels = {'positive':0,'neutral':0,'negative':0}\n","  start_num = 0\n","  for i, label in enumerate(labels):\n","    end_num = start_num+len(df.loc[df.labels == i])\n","    TP = torch.sum(y[start_num:end_num] == y_hat[start_num:end_num])\n","    the_last = torch.cat((y_hat[:start_num],y_hat[end_num:]))\n","    FP = torch.count_nonzero( the_last == i)\n","    FN = torch.count_nonzero( y_hat[start_num:end_num] != i)\n","    print('Precision of',label, ': ', TP/(TP+FP))\n","    F1 = 2*TP / (2*TP+FP+FN)\n","    labels[label] = round(F1.item(),2)\n","    start_num = len(df.loc[df.labels == i])\n","  accuracy = torch.sum(y==y_hat)/float(len(y))\n","  print('F1_score of every label: ', labels)\n","  print('Average F1: ',round(statistics.mean(labels.values()),2))\n","  print('Accuracy: ', accuracy)"],"metadata":{"id":"mYYJTVVTgFgj","executionInfo":{"status":"ok","timestamp":1698587392142,"user_tz":-420,"elapsed":2,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["# metric()"],"metadata":{"id":"fJ5DJb2chC07","executionInfo":{"status":"ok","timestamp":1698587488770,"user_tz":-420,"elapsed":4,"user":{"displayName":"Hoang Ngoc Xuan Nguyen (K17 HCM)","userId":"06162354724359960596"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JjccNhcssrPV"},"execution_count":null,"outputs":[]}]}