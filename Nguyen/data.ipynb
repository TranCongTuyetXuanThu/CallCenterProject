{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to-do list\n",
    "1) extract feature\n",
    "2) label ([exc, hap, sur] 21%,[neu, fru] 42%,[fea, ang, sad, dis] 38%) -> 1 file.csv\n",
    "3) process dims (double), bias (remove)\n",
    "- add noise\n",
    "- process real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchaudio\n",
    "# !pip install torch\n",
    "# !pip install soundfile\n",
    "#!pip install PySoundFile\n",
    "# print(torchaudio.__version__)\n",
    "# print(torch.__version__)\n",
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoang\\AppData\\Local\\Temp\\ipykernel_6668\\1226341598.py:5: DeprecationWarning: 'sndhdr' is deprecated and slated for removal in Python 3.13\n",
      "  import sndhdr\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import torchaudio\n",
    "from io import StringIO\n",
    "import torch\n",
    "import sndhdr\n",
    "import soundfile\n",
    "import numpy\n",
    "import csv,glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) EXTRACT FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_data():\n",
    "    # Define the path to your data folder\n",
    "    data_folder_path = os.path.join('..', 'IEMOCAP_release_full')\n",
    "\n",
    "    # Create a link to the data folder\n",
    "    data_folder_link = os.path.dirname(os.path.abspath(data_folder_path))\n",
    "\n",
    "    # Print the link\n",
    "    return(data_folder_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Đọc link file\n",
    "def read_link_wav(type = ('sentences', 'dialog'), sessions = [1,2,3,4,5]):\n",
    "    source = link_to_data()\n",
    "    link = os.path.join(source,'IEMOCAP_full_release', 'Session'+str(sessions), type, 'wav')\n",
    "    links = {}\n",
    "    if type == 'dialog':\n",
    "        return\n",
    "    for dialog in os.listdir(link):\n",
    "        list_sentence = []\n",
    "        for sentence in os.listdir(os.path.join(link,dialog)):\n",
    "            sentence_link = os.path.join(link, dialog, sentence)\n",
    "            list_sentence.append(sentence_link)\n",
    "        links[dialog] = list_sentence\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#.wav to .pt\n",
    "def read_and_save_mfcc(types = ('dialog','sentences')):\n",
    "    for session in range(1,6):\n",
    "        links = read_link_wav(types, session)\n",
    "        source = link_to_data()\n",
    "        root = os.path.join(source,'IEMOCAP_full_release','Session'+str(session),types)\n",
    "        if os.path.exists(os.path.join(root,'mfcc')):\n",
    "            shutil.rmtree(os.path.join(root,'mfcc'))\n",
    "        os.makedirs(os.path.join(root,'mfcc'))\n",
    "        for dia in links.keys():\n",
    "            if os.path.exists(os.path.join(root,'mfcc',dia)):\n",
    "                shutil.rmtree(os.path.join(root,'mfcc',dia))\n",
    "            os.makedirs(os.path.join(root,'mfcc',dia))\n",
    "            for sen in links[dia]:\n",
    "                try:\n",
    "                    if sndhdr.what(sen).filetype == 'wav':\n",
    "                        waveform, sample_rate = torchaudio.load(sen)\n",
    "                        transform = torchaudio.transforms.MFCC(sample_rate=sample_rate)\n",
    "                        mfcc = transform(waveform)\n",
    "                        output_file = os.path.join(root,'mfcc',dia,os.path.basename(sen)[:-4]+'.pt')\n",
    "                        torch.save(mfcc,output_file)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract feature .wav to .pt\n",
    "# read_and_save_mfcc('sentences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Label + remove noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_shape(file):\n",
    "    mfcc = torch.load(file)\n",
    "    return list(mfcc.shape)\n",
    "def update_sample(categories,session,words):\n",
    "    source = link_to_data()\n",
    "    if len(words)==4:\n",
    "        path_file = os.path.join(source,'IEMOCAP_full_release','Session'+str(session),'sentences','mfcc',words[1][:-5],words[1]+'.pt')\n",
    "        if os.path.exists(path_file):\n",
    "            shape = get_shape(path_file)\n",
    "            with open('processed_label_data.csv',mode = 'a',newline = '') as f:\n",
    "                write = csv.writer(f)\n",
    "                if (words[2]) in categories['positive']:\n",
    "                    write.writerow([words[1],words[2],1,0,0,shape,shape[1:],path_file])\n",
    "                if (words[2]) in categories['neutral']:\n",
    "                    write.writerow([words[1],words[2],0,1,0,shape,shape[1:],path_file])\n",
    "                if (words[2]) in categories['negative']:\n",
    "                    write.writerow([words[1],words[2],0,0,1,shape,shape[1:],path_file])\n",
    "                if (words[2]) in ['xxx','oth']:\n",
    "                    os.remove(path_file)\n",
    "def create_label_file():\n",
    "    source = link_to_data()\n",
    "    categories = {'positive': ['exc', 'hap', 'sur'],\n",
    "                'neutral': ['neu','fru'],\n",
    "                'negative': ['fea','ang','sad','dis']}\n",
    "    header = ['sessionID','labels','positive','neutral','negative','dims','time_shape','path']\n",
    "    with open('processed_label_data.csv',mode='w',newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    for session in range(1,6):\n",
    "        root = os.path.join(source,'IEMOCAP_full_release','Session'+str(session),'dialog','EmoEvaluation','*')\n",
    "        files = glob.glob(root)\n",
    "        for file in files:\n",
    "            if file[-3:] =='txt': \n",
    "                with open(file, 'r') as lines:\n",
    "                    for line in lines:\n",
    "                        words = line.split(\"\\t\")\n",
    "                        update_sample(categories,session,words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_label_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for mono file audio or not\n",
    "def check_mono():\n",
    "    source = link_to_data()\n",
    "    for session in range(1,6):\n",
    "        root = os.path.join(source,'IEMOCAP_full_release','Session'+str(session),'sentences','mfcc')\n",
    "        for dialog in os.listdir(root):\n",
    "            for sentence in os.listdir(os.path.join(root,dialog)):\n",
    "                sample = torch.load(os.path.join(root,dialog,sentence))\n",
    "                if sample.shape[0]!=1:\n",
    "                    return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reform_file_data():\n",
    "    df = pd.read_csv('processed_label_data.csv')\n",
    "    df['dims'] = df['dims'].apply(lambda x: [int(i) for i in x.strip('[]').split(',')])\n",
    "    if str(df['time_shape'].dtype) == 'object':\n",
    "        df['time_shape'] = df['time_shape'].apply(lambda x: int(x.strip('[]')))\n",
    "    df.to_csv('processed_label_data.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to size(128,1500)\n",
    "def normalize_shape():\n",
    "    df = reform_file_data()\n",
    "    for sample in range(len(df)):\n",
    "        tmp_sample = torch.load(df.path[sample])\n",
    "        if len(tmp_sample.shape) == 3:\n",
    "            tmp_sample = tmp_sample.resize(40,tmp_sample.shape[2])\n",
    "        if tmp_sample.shape[1] == 1500:\n",
    "            continue\n",
    "        if tmp_sample.shape[1] >1500:\n",
    "            tmp_sample = tmp_sample[:,:1500]\n",
    "        while tmp_sample.shape[1]<1500:\n",
    "            last_dims = 1500 - tmp_sample.shape[1]\n",
    "            if last_dims > tmp_sample.shape[1]:\n",
    "                tmp_sample = torch.cat((tmp_sample,tmp_sample),dim=1)\n",
    "            else:\n",
    "                tmp_sample = torch.cat((tmp_sample,tmp_sample[:,:last_dims]),dim=1)\n",
    "        torch.save(tmp_sample,df.path[sample])\n",
    "        df['time_shape'][sample] = 1500\n",
    "        df['dims'][sample] = [40,1500]\n",
    "    df.to_csv('processed_shape_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_shape():\n",
    "    df = reform_file_data()\n",
    "    for sample in range(len(df)):\n",
    "        tmp_sample = torch.load(df.path[sample])\n",
    "        if list(tmp_sample.shape) != [40,1500]:\n",
    "            print(list(tmp_sample.shape))\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_shape()\n",
    "check_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Standard scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scalling\n",
    "def StandardScalling(x_train, x_test):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    N,H,W = x_train.shape # N: number of sample, W: weight, H: height\n",
    "    # standard scale use for only 1-D array\n",
    "    x_train = np.reshape(x_train, (N, -1))\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_train = np.reshape(x_train, (N,H,W))\n",
    "\n",
    "    N,H,W = x_test.shape # N: number of sample, W: weight, H: height\n",
    "    # standard scale use for only 1-D array\n",
    "    x_test = np.reshape(x_test, (N, -1))\n",
    "    x_test = scaler.fit_transform(x_train)\n",
    "    x_test = np.reshape(x_test, (N,H,W))    \n",
    "\n",
    "    # check shape of each set again\n",
    "    print(f'X_train scaled:{X_train.shape}, y_train:')\n",
    "    print(f'X_test scaled:{X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corrNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
