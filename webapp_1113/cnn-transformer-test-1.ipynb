{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-13T02:56:39.229177Z","iopub.execute_input":"2023-11-13T02:56:39.229597Z","iopub.status.idle":"2023-11-13T02:56:39.826442Z","shell.execute_reply.started":"2023-11-13T02:56:39.229563Z","shell.execute_reply":"2023-11-13T02:56:39.824905Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dpl-project/model93.pt\n/kaggle/input/dpl-project/features_labels_balanced.npy\n/kaggle/input/dpl-project/model_update1.pt\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_05.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_03.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_10.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_14.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_09.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_14.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_7.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_9.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_8.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_12.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_01.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_08.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_06.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_11.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_18.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_04.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_17.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_14.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_3.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_05.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_11.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_09.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_10.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_13.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_15.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_11.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_02.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_16.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_11.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_17.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_06.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_06.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_16.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_13.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_5.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_10.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_02.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_15.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_16.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_04.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_14.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_07.mp4\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_13.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_01.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_07.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_08.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_17.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_03.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_07.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_08.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_03.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_01.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_05.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_12.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_12.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_02.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_13.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_6.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_09.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_2.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_4.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/chien_12.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_15.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Xuyen_04.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/Nhat_10.aac\n/kaggle/input/dpl-project/test_data/raw_datas/neutral/tinh_1.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_16.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_05.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_20.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_03.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_10.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_14.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_12.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_05.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_03.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_14.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_13.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_7.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_9.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_08.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_06.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_8.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_12.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_01.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_15.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_22.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_06.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_11.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_18.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_04.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_15.aac\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_04.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_02.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_10.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_17.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_06.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_3.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_11.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_08.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_10.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_15.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_15.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_02.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_16.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_17.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_11.mp4\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_06.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_19.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_05.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_12.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_14.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_16.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_13.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_23.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_5.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_17.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_07.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_07.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_10.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_09.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_14.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_01.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_13.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_13.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_21.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_03.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_07.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_17.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_16.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_03.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_14.aac\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_09.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_08.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_10.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_08.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_05.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_01.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_12.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_11.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_16.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_11.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_07.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/chien_02.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/anh_04.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_6.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_24.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_09.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_09.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_2.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_4.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_02.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_17.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_13.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_15.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Xuyen_04.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_01.wav\n/kaggle/input/dpl-project/test_data/raw_datas/negative/tinh_1.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_16.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_05.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_03.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_10.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_14.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_12.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_09.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_14.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_13.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_7.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_9.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_8.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_07.mp3\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_12.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_11.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_01.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_06.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_11.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_12.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_15.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_04.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_02.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_17.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_10.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_17.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_06.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_14.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_3.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_05.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_11.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_09.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_13.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_15.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_15.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_11.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_02.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_16.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_17.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_06.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_05.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_14.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_06.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_16.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_13.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_5.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_17.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_07.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_10.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_09.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_02.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_15.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_16.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_01.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_08.mp4\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_04.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_14.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_13.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_01.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_03.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_07.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_08.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_17.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_03.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_07.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_08.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_03.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_08.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_01.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_05.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_12.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_16.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_11.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_12.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_02.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_13.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/anh_04.wav\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_6.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_09.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_2.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_4.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_15.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/chien_10.mp4\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Xuyen_04.m4a\n/kaggle/input/dpl-project/test_data/raw_datas/positive/Nhat_10.aac\n/kaggle/input/dpl-project/test_data/raw_datas/positive/tinh_1.m4a\n","output_type":"stream"}]},{"cell_type":"code","source":"import subprocess, os, csv\nfrom torch import nn\nimport torch, torchaudio, statistics\nfrom pydub import AudioSegment\nfrom pydub.silence import detect_nonsilent\nimport pandas as pd\nimport warnings, shutil\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2023-11-13T02:56:39.828888Z","iopub.execute_input":"2023-11-13T02:56:39.829583Z","iopub.status.idle":"2023-11-13T02:56:45.929702Z","shell.execute_reply.started":"2023-11-13T02:56:39.829533Z","shell.execute_reply":"2023-11-13T02:56:45.928552Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# suppress all warnings\nwarnings.filterwarnings(\"ignore\")\n# suppress only the UserWarning with message \"At least one mel filterbank has all zero values.\"\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-11-13T02:58:06.915103Z","iopub.execute_input":"2023-11-13T02:58:06.916233Z","iopub.status.idle":"2023-11-13T02:58:06.923622Z","shell.execute_reply.started":"2023-11-13T02:58:06.916179Z","shell.execute_reply":"2023-11-13T02:58:06.922563Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Model flow\nclass define_model(nn.Module):\n\n    # Define layers\n    def __init__(self, num_emotions):\n        super().__init__()\n\n        transformer_layer = nn.TransformerEncoderLayer(\n            d_model=40, #####################\n            nhead=4,\n            dim_feedforward=512,\n            dropout=0.4,\n            activation='relu'\n        )\n        self.transformer_maxpool = nn.MaxPool2d(kernel_size=[1,4], stride=[1,4])\n        self.transformer_encoder = nn.TransformerEncoder(transformer_layer, num_layers=4)\n\n        #maxpool: reshape (width, height)\n        #conv: reshape (channel)\n        conv2d_layer = nn.Sequential(\n            nn.Conv2d(\n                in_channels=2,\n                out_channels=16,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(16),#######\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Dropout(p=0.3),\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(32),#######\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4, stride=4),\n            nn.Dropout(p=0.3),\n            nn.Conv2d(\n                in_channels=32,\n                out_channels=64,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(64),#######\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4, stride=4),\n            nn.Dropout(p=0.3),\n        )\n        self.conv2Dblock1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=2,\n                out_channels=16,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Dropout(p=0.3),\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4, stride=4),\n            nn.Dropout(p=0.3),\n            nn.Conv2d(\n                in_channels=32,\n                out_channels=64,\n                kernel_size=3,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4, stride=4),\n            nn.Dropout(p=0.3),\n        )\n        self.conv2Dblock2 = conv2d_layer\n\n        self.fc1_layer = nn.Linear(1792*2+40, 1800)\n        self.act1 = nn.ReLU()\n        self.fc2_layer = nn.Linear(1800, num_emotions)\n        self.softmax_out = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        conv2d_embedding1 = self.conv2Dblock1(x)\n        conv2d_embedding1 = torch.flatten(conv2d_embedding1, start_dim = 1)\n\n        conv2d_embedding2 = self.conv2Dblock2(x)\n        conv2d_embedding2 = torch.flatten(conv2d_embedding2, start_dim = 1)\n\n        x_maxpool = self.transformer_maxpool(x)\n        # x_maxpool_reduced = torch.squeeze(x_maxpool,1) \n        x_maxpool_reduced = x_maxpool.resize(x_maxpool.shape[0], 40, 450) \n        x = x_maxpool_reduced.permute(2,0,1) #rearrange dims\n        transformer_output = self.transformer_encoder(x)\n        transformer_embedding = torch.mean(transformer_output, dim = 0)\n\n        complete_embedding = torch.cat([conv2d_embedding1, conv2d_embedding2, transformer_embedding], dim = 1)\n        fc1 = self.fc1_layer(complete_embedding)\n        ac1 = self.act1(fc1)\n        output_logits = self.fc2_layer(ac1)\n        output_softmax = self.softmax_out(output_logits)\n        return output_logits, output_softmax","metadata":{"execution":{"iopub.status.busy":"2023-11-13T02:58:08.313494Z","iopub.execute_input":"2023-11-13T02:58:08.314304Z","iopub.status.idle":"2023-11-13T02:58:08.339308Z","shell.execute_reply.started":"2023-11-13T02:58:08.314264Z","shell.execute_reply":"2023-11-13T02:58:08.338097Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class preprocess_real_data():\n    def __init__(self,file):\n      self.file = file\n    def mp4_to_wav(self, file):\n        output_file = file.replace('input/dpl-project/test_data/raw_datas', 'working/wav_datas')\n        output_file = output_file.split('.')[0] + \".wav\"\n        subprocess.call(['ffmpeg', '-i', file, output_file])\n        return output_file\n    def remove_noise(self, file):\n        # Detect non-silent parts of the audio\n        sound_file = AudioSegment.from_wav(file)\n        non_sil_times = detect_nonsilent(sound_file, min_silence_len=400, silence_thresh=sound_file.dBFS * 0.65)\n        # Concatenate the non-silent parts of the audio\n        if len(non_sil_times) > 0:\n            non_sil_times_concat = [non_sil_times[0]]\n            if len(non_sil_times) > 1:\n                for t in non_sil_times[1:]:\n                    if t[0] - non_sil_times_concat[-1][1] < 100:\n                        non_sil_times_concat[-1] = (non_sil_times_concat[-1][0], t[1])\n                    else:\n                        non_sil_times_concat.append(t)\n            new_audio = sound_file[non_sil_times_concat[0][0]:non_sil_times_concat[0][1]]\n            for t in non_sil_times_concat[1:]:\n                new_audio += sound_file[t[0]:t[1]]\n        else:\n            new_audio = sound_file\n\n        # Export the new audio file\n        file_name = file.replace('wav_datas', 'denoised_datas')\n        file_name = file_name[:-4]+'_denoised.wav'\n        new_audio.export(file_name, format=\"wav\")\n        return file_name\n    def resize(self, file):\n        tensor = torch.load(file)\n        n = tensor.shape[-1]//900 + 1\n        sample = torch.zeros((2,40,n * 900))\n        sample[:,:,:tensor.shape[-1]] = tensor\n        sample = sample.reshape((2,40,900,n)).permute(3,0,1,2)\n        torch.save(sample,file)\n#         sample = torch.transpose(torch.transpose(sample1.reshape((40,500,n)),dim0=0, dim1=2),dim0=1, dim1=2).reshape((n,1,40,500))\n        return sample\n    def save_tensor_file(self, file):\n        waveform, sample_rate = torchaudio.load(file)\n        transform = torchaudio.transforms.MFCC(sample_rate=sample_rate)\n        mfcc = transform(waveform)\n        file_name = file[:-4]+'.pt'\n        torch.save(mfcc,file_name)\n        return file_name\n    def complete_preprocessing(self, file):\n      file = self.mp4_to_wav(file)\n      file = self.remove_noise(file)\n      file = self.save_tensor_file(file)\n      tensor = self.resize(file)\n      return file, tensor","metadata":{"execution":{"iopub.status.busy":"2023-11-13T02:58:09.198368Z","iopub.execute_input":"2023-11-13T02:58:09.198824Z","iopub.status.idle":"2023-11-13T02:58:09.217666Z","shell.execute_reply.started":"2023-11-13T02:58:09.198789Z","shell.execute_reply":"2023-11-13T02:58:09.216459Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def load_model(model_path):\n    model = define_model(3)\n    model.eval()\n    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n#     model.load_state_dict(torch.load(model_path))\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-13T02:58:10.339058Z","iopub.execute_input":"2023-11-13T02:58:10.339817Z","iopub.status.idle":"2023-11-13T02:58:10.345544Z","shell.execute_reply.started":"2023-11-13T02:58:10.339778Z","shell.execute_reply":"2023-11-13T02:58:10.344387Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# model = load_model('/kaggle/input/dpl-project/model93.pt')\n# # model = torch.load('/kaggle/input/dpl-project/model_update1.pt', map_location='cpu')\n# # model.load_state_dict(torch.load('model.pt'))\n# # model.parameters()\n# num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n# print(f'Total number of trainable parameters: {num_params}')","metadata":{"execution":{"iopub.status.busy":"2023-11-13T02:58:16.134870Z","iopub.execute_input":"2023-11-13T02:58:16.135331Z","iopub.status.idle":"2023-11-13T02:58:16.924630Z","shell.execute_reply.started":"2023-11-13T02:58:16.135295Z","shell.execute_reply":"2023-11-13T02:58:16.923530Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Total number of trainable parameters: 6770659\n","output_type":"stream"}]},{"cell_type":"code","source":"import wave\n\ndef get_wav_duration(file_path):\n    with wave.open(file_path, 'rb') as wav_file:\n        # Get the frame rate (samples per second) and total number of frames\n        frame_rate = wav_file.getframerate()\n        total_frames = wav_file.getnframes()\n\n        # Calculate the duration in seconds\n        duration = total_frames / float(frame_rate)\n    \n    return duration","metadata":{"execution":{"iopub.status.busy":"2023-11-13T05:38:54.577535Z","iopub.execute_input":"2023-11-13T05:38:54.577999Z","iopub.status.idle":"2023-11-13T05:38:54.585856Z","shell.execute_reply.started":"2023-11-13T05:38:54.577968Z","shell.execute_reply":"2023-11-13T05:38:54.584854Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"def predict_real_time(file_sample, model, preprocesser):\n    _, tensor = preprocesser.complete_preprocessing(file_sample)\n    output_logit, output_softmax = model(tensor)\n    output_softmax = torch.argmax(output_softmax, dim=1)\n    emotion_dict = {0: 'positive',\n                    1: 'neutral',\n                    2: 'negative'}\n    labels = [emotion_dict[int(value)] for value in output_softmax]\n    \n    final_output = max(set(output_softmax.tolist()), key=output_softmax.tolist().count)\n    label = emotion_dict[final_output]\n    \n    duration_seconds = get_wav_duration(file_sample)\n    range_ = duration_seconds/ len(labels)\n    a = datetime.time(0, 0)\n    list_labels = list()\n    delta = datetime.timedelta(seconds=round(range_, 5))\n    for label in labels:\n        new_time = datetime.datetime.combine(datetime.datetime.today(), a) + delta\n        list_labels.append(str(a)[3:8]+'-'+str(new_time.time())[3:8]+'_'+str(label))\n        a = new_time.time()\n    return(list_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T05:48:22.807690Z","iopub.execute_input":"2023-11-13T05:48:22.808182Z","iopub.status.idle":"2023-11-13T05:48:22.820978Z","shell.execute_reply.started":"2023-11-13T05:48:22.808146Z","shell.execute_reply":"2023-11-13T05:48:22.819333Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"preprocesser = preprocess_real_data(0)\nmodel = load_model('/kaggle/input/dpl-project/model93.pt')\nfile_sample = '/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_02.wav'\npredict_real_time(file_sample, model, preprocesser)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T05:48:23.114500Z","iopub.execute_input":"2023-11-13T05:48:23.114922Z","iopub.status.idle":"2023-11-13T05:48:24.155589Z","shell.execute_reply.started":"2023-11-13T05:48:23.114890Z","shell.execute_reply":"2023-11-13T05:48:24.154319Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stderr","text":"ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 31.100 / 56. 31.100\n  libavcodec     58. 54.100 / 58. 54.100\n  libavformat    58. 29.100 / 58. 29.100\n  libavdevice    58.  8.100 / 58.  8.100\n  libavfilter     7. 57.100 /  7. 57.100\n  libavresample   4.  0.  0 /  4.  0.  0\n  libswscale      5.  5.100 /  5.  5.100\n  libswresample   3.  5.100 /  3.  5.100\n  libpostproc    55.  5.100 / 55.  5.100\nGuessed Channel Layout for Input Stream #0.0 : stereo\nInput #0, wav, from '/kaggle/input/dpl-project/test_data/raw_datas/negative/Nhat_02.wav':\n  Metadata:\n    encoder         : Lavf59.27.100\n  Duration: 00:00:08.62, bitrate: 1536 kb/s\n    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\nFile '/kaggle/working/wav_datas/negative/Nhat_02.wav' already exists. Overwrite ? [y/N] Not overwriting - exiting\n","output_type":"stream"},{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"['00:00-00:02_neutral', '00:02-00:05_neutral', '00:05-00:08_neutral']"},"metadata":{}}]},{"cell_type":"code","source":"def predict_1_sample(file_sample, model):\n    tensor = torch.load(file_sample)\n    output_logit, output_softmax = model(tensor)\n    output_softmax = torch.argmax(output_softmax, dim=1)\n    final_output = max(set(output_softmax.tolist()), key=output_softmax.tolist().count)\n    emotion_dict = {0: 'positive',\n                    1: 'neutral',\n                    2: 'negative'}\n    label = emotion_dict[final_output]\n    return final_output, label","metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:39:54.653999Z","iopub.execute_input":"2023-11-13T03:39:54.654718Z","iopub.status.idle":"2023-11-13T03:39:54.663807Z","shell.execute_reply.started":"2023-11-13T03:39:54.654649Z","shell.execute_reply":"2023-11-13T03:39:54.662336Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def extract_label_file(root):\n  header = ['sessionID','labels','path']\n  emotion_dict = {\n      'positive': 0,\n    absolute  'neutral': 1,\n      'negative': 2\n  }\n  with open('test_real_data.csv',mode='w',newline='') as file:\n          write = csv.writer(file)\n          write.writerow(header)\n  df = pd.read_csv('test_real_data.csv')\n  for file in os.listdir(root):\n          for sample in os.listdir(os.path.join(root, file)):\n              processer = preprocess_real_data(0)\n              path_sample, tensor = processer.complete_preprocessing(os.path.join(root, file, sample))\n              sample_info = {'sessionID': sample, 'labels': emotion_dict[file],'path': path_sample}\n              df = pd.concat([df, pd.DataFrame([sample_info])], ignore_index=True)\n  df.to_csv('test_real_data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:00:23.787395Z","iopub.execute_input":"2023-11-13T03:00:23.787831Z","iopub.status.idle":"2023-11-13T03:00:23.799752Z","shell.execute_reply.started":"2023-11-13T03:00:23.787800Z","shell.execute_reply":"2023-11-13T03:00:23.798196Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def test_real_data(model_file):\n  df = pd.read_csv('/kaggle/working/test_real_data.csv')\n  df = df.sort_values('labels')\n  model = load_model(model_file)\n  preprocesser = preprocess_real_data('ok')\n  y = df.labels\n  y = torch.as_tensor(y)\n  y_hat = torch.zeros(len(y))\n  ind_sample = 0\n  for sample in df.path:\n    final_output, label = predict_1_sample(sample, model)\n    y_hat[ind_sample] = final_output\n    ind_sample += 1\n  df.to_csv('/kaggle/working/test_real_data.csv')\n  return y, y_hat","metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:00:25.336509Z","iopub.execute_input":"2023-11-13T03:00:25.337003Z","iopub.status.idle":"2023-11-13T03:00:25.346793Z","shell.execute_reply.started":"2023-11-13T03:00:25.336970Z","shell.execute_reply":"2023-11-13T03:00:25.345279Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# shutil.rmtree('/kaggle/working/wav_datas')\n# shutil.rmtree('/kaggle/working/denoised_datas')\n# folder_root = ['denoised_datas','wav_datas']\n# folder = ['positive','neutral','negative']\n# for fold in folder_root:\n#     os.makedirs(os.path.join('/kaggle/working/',fold))\n#     for fold_ in folder:\n#         os.makedirs(os.path.join('/kaggle/working/',fold,fold_))","metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:00:54.283124Z","iopub.execute_input":"2023-11-13T03:00:54.283575Z","iopub.status.idle":"2023-11-13T03:00:54.290262Z","shell.execute_reply.started":"2023-11-13T03:00:54.283540Z","shell.execute_reply":"2023-11-13T03:00:54.288890Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# root = '/kaggle/input/dpl-project/test_data/raw_datas'\n# extract_label_file(root)\n# model_file = '/kaggle/input/dpl-project/model93.pt'\n# y, y_hat = test_real_data(model_file)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-11-13T03:29:41.398127Z","iopub.execute_input":"2023-11-13T03:29:41.398601Z","iopub.status.idle":"2023-11-13T03:29:41.404483Z","shell.execute_reply.started":"2023-11-13T03:29:41.398565Z","shell.execute_reply":"2023-11-13T03:29:41.403210Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/test_real_data.csv')\nmodel_file = '/kaggle/input/dpl-project/model93.pt'\nmodel = load_model(model_file)\npath = df.path[0]\nprint(path)\nsoftmax, final_output, label, labels = predict_1_sample(path, model)\nsoftmax, final_output, label, labels\n","metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:39:58.600003Z","iopub.execute_input":"2023-11-13T03:39:58.600504Z","iopub.status.idle":"2023-11-13T03:39:59.041517Z","shell.execute_reply.started":"2023-11-13T03:39:58.600464Z","shell.execute_reply":"2023-11-13T03:39:59.040157Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"/kaggle/working/denoised_datas/neutral/chien_05_denoised.pt\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(tensor([1, 1, 1, 1, 1, 1]),\n 1,\n 'neutral',\n ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral'])"},"metadata":{}}]},{"cell_type":"code","source":"# from IPython.display import Audio\nsample, sample_rate = torchaudio.load('/kaggle/working/denoised_datas/neutral/chien_05_denoised.wav')\nprint(Audio(sample, rate=sample_rate))\nduration_seconds = len(sample) * 10**6 / sample_rate\nprint(f\"Duration: {round(duration_seconds)} seconds\")\nrange_ = duration_seconds/ len(labels)\nprint(round(range_))","metadata":{"execution":{"iopub.status.busy":"2023-11-13T05:02:22.279992Z","iopub.execute_input":"2023-11-13T05:02:22.280533Z","iopub.status.idle":"2023-11-13T05:02:22.322971Z","shell.execute_reply.started":"2023-11-13T05:02:22.280494Z","shell.execute_reply":"2023-11-13T05:02:22.320849Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"<IPython.lib.display.Audio object>\nDuration: 23 seconds\n4\n","output_type":"stream"}]},{"cell_type":"code","source":"def metric(y, y_hat):\n  df = pd.read_csv('/kaggle/working/test_real_data.csv')\n  labels = {'positive':0,'neutral':0,'negative':0}\n  start_num = 0\n  for i, label in enumerate(labels):\n    end_num = start_num+len(df.loc[df.labels == i])\n    TP = torch.sum(y[start_num:end_num] == y_hat[start_num:end_num])\n    the_last = torch.cat((y_hat[:start_num],y_hat[end_num:]))\n    FP = torch.count_nonzero( the_last == i)\n    FN = torch.count_nonzero( y_hat[start_num:end_num] != i)\n#     print('Precision of',label, ': ', TP/(TP+FP))\n    F1 = 2*TP / (2*TP+FP+FN)\n    labels[label] = round(F1.item(),2)\n    start_num = end_num\n  accuracy = torch.sum(y==y_hat)/float(len(y))\n  print('F1_score of every label: ', labels)\n  print('Average F1: ',round(statistics.mean(labels.values()),2))\n  print('Accuracy: ', accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T07:20:30.938832Z","iopub.execute_input":"2023-11-01T07:20:30.939147Z","iopub.status.idle":"2023-11-01T07:20:30.946666Z","shell.execute_reply.started":"2023-11-01T07:20:30.939122Z","shell.execute_reply":"2023-11-01T07:20:30.945747Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"metric(y, y_hat)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T07:20:31.645151Z","iopub.execute_input":"2023-11-01T07:20:31.645509Z","iopub.status.idle":"2023-11-01T07:20:31.659369Z","shell.execute_reply.started":"2023-11-01T07:20:31.645454Z","shell.execute_reply":"2023-11-01T07:20:31.658230Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"Precision of positive :  tensor(0.3696)\nPrecision of neutral :  tensor(0.3128)\nPrecision of negative :  tensor(0.)\nF1_score of every label:  {'positive': 0.26, 'neutral': 0.47, 'negative': 0.0}\nAverage F1:  0.24\nAccuracy:  tensor(0.3223)\n","output_type":"stream"}]}]}